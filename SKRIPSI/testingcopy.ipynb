{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analys The Problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously on papper \"Facial Expression Recognition Methods in the Wild Based on Fusion Feature of Attention Mechanism and LBP (MDPI Sensors 2023 Q2)\" authors used a model called ResNet-50 combined CBAM and LBP.\n",
    "\n",
    "The accuracy took:\n",
    "- 99.66% on CK+\n",
    "- 74.23% on FER-2013\n",
    "- 89.50 on FER-PLUS \n",
    "- 88.20 on RAF-DB\n",
    "\n",
    "**The problem: What if I change the variant of LBP in this method, does it increase the accuracy spesifically for FER-2013 dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **About Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The paper used 4 dataset include CK+(59 images), FER-2013 (35,887 images), FER-PLUS(31.412 images), RAF-DB (29,672 images)\n",
    "- CK+ is a controlled dataset and the 3 others datasets are uncontrolled datasets\n",
    "- Controlled dataset has good lightning and pose but uncontrolled datasets got a random of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ResNet-18 + CBAM**\n",
    "\n",
    "    1. Architecture of ResNet-18:\n",
    "    \n",
    "        <img src=\"../src/Structure-of-a-ResNet-18-architecture.png\" alt=\"Windowing of Feature in Faces\" width=\"350\" height=\"250\">\n",
    "\n",
    "    2. CBAM Architecture:\n",
    "\n",
    "        <img src=\"../src/cbam.png\" alt=\"Windowing of Feature in Faces\" width=\"600\" height=\"100\">\n",
    "\n",
    "    3. Authors combine the CBAM module into each block of the ResNet-18 architecture,\n",
    "    \n",
    "        Before and After implement the CBAM module:\n",
    "\n",
    "        <img src=\"../src/oriblock.png\" alt=\"Windowing of Feature in Faces\" width=\"150\" height=\"200\">\n",
    "        <img src=\"../src/blocknCbam.png\" alt=\"Windowing of Feature in Faces\" width=\"150\" height=\"200\">\n",
    "\n",
    "- **Local Binary Patterns (LBP)**\n",
    "\n",
    "    LBP is one of the most generally used texture pattern descriptors for examining local grain features and is regarded as one of the best methods for texture processing, which is widely employed in image processing.\n",
    "\n",
    "- **RCL-Net Model**\n",
    "\n",
    "    After combining all the method such as LBP and ResNet-CBAM, this architecture called by **RCL-Net Model**,\n",
    "\n",
    "    <img src=\"../src/rcl-net.png\" alt=\"Windowing of Feature in Faces\" width=\"700\" height=\"200\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In planning, switching LBP method in previous architecture with the newest or other variant LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# for augmen:\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# for mixup augmen:\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# mixup from train.py file\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# LBP\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_train = pd.read_csv('afterAugTrain.csv')\n",
    "df_public_test = pd.read_csv('afterAugTest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize datatable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.53333336 0.5058824 0.4509804 0.39215687 0.34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.09803922 0.09019608 0.07058824 0.06666667 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.8980392 0.8862745 0.87058824 0.84705883 0.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.8627451 0.8745098 0.88235295 0.8980392 0.878...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.2784314 0.30980393 0.3647059 0.42352942 0.42...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     usage                                     resized_pixels\n",
       "0        0  Training  0.53333336 0.5058824 0.4509804 0.39215687 0.34...\n",
       "1        0  Training  0.09803922 0.09019608 0.07058824 0.06666667 0....\n",
       "2        0  Training  0.8980392 0.8862745 0.87058824 0.84705883 0.83...\n",
       "3        0  Training  0.8627451 0.8745098 0.88235295 0.8980392 0.878...\n",
       "4        0  Training  0.2784314 0.30980393 0.3647059 0.42352942 0.42..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilan hasil original + augmentasi dataframe setelah normalisasi\n",
    "df_combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.00390619 0.00390619 0.00390619 0.00390619 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.00236832 0.002475971 0.002675894 0.002906574...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.00092272204 0.0012302961 0.0016916571 0.0017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.0032602844 0.0031372549 0.0029680892 0.00316...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.0013225683 0.0013071896 0.0012610535 0.00121...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion       usage                                     resized_pixels\n",
       "0        0  PublicTest  0.00390619 0.00390619 0.00390619 0.00390619 0....\n",
       "1        1  PublicTest  0.00236832 0.002475971 0.002675894 0.002906574...\n",
       "2        4  PublicTest  0.00092272204 0.0012302961 0.0016916571 0.0017...\n",
       "3        6  PublicTest  0.0032602844 0.0031372549 0.0029680892 0.00316...\n",
       "4        3  PublicTest  0.0013225683 0.0013071896 0.0012610535 0.00121..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilan hasil df_public_test dataframe setelah normalisasi\n",
    "df_public_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom emotion: Jika ini adalah label kelas, awalnya tipe object maka bisa mengubahnya menjadi tipe data numerik menggunakan LabelEncoder dari scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_combined_train['emotion'] = le.fit_transform(df_combined_train['emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom resized_pixels: Jika kolom ini berisi string yang merepresentasikan array alias saat ini tipe object, maka perlu mengubahnya menjadi array numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi string piksel menjadi array NumPy data train\n",
    "df_combined_train['resized_pixels'] = df_combined_train['resized_pixels'].apply(\n",
    "    lambda x: np.fromstring(x, sep=' ').astype(np.float32).reshape(100, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6104 entries, 0 to 6103\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   emotion         6104 non-null   int64 \n",
      " 1   usage           3052 non-null   object\n",
      " 2   resized_pixels  6104 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_combined_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi string piksel menjadi array NumPy data test\n",
    "df_public_test.loc[:, 'resized_pixels'] = df_public_test['resized_pixels'].apply(\n",
    "    lambda x: np.fromstring(x, sep=' ').astype(np.float32).reshape(100, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Pastikan semua entri memiliki ukuran 100x100\n",
    "print(df_combined_train['resized_pixels'].apply(lambda x: x.shape == (100, 100)).all())\n",
    "print(df_public_test['resized_pixels'].apply(lambda x: x.shape == (100, 100)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.53333336, 0.5058824, 0.4509804, 0.39215687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.09803922, 0.09019608, 0.07058824, 0.066666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.8980392, 0.8862745, 0.87058824, 0.84705883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.8627451, 0.8745098, 0.88235295, 0.8980392,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.2784314, 0.30980393, 0.3647059, 0.42352942...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     usage                                     resized_pixels\n",
       "0        0  Training  [[0.53333336, 0.5058824, 0.4509804, 0.39215687...\n",
       "1        0  Training  [[0.09803922, 0.09019608, 0.07058824, 0.066666...\n",
       "2        0  Training  [[0.8980392, 0.8862745, 0.87058824, 0.84705883...\n",
       "3        0  Training  [[0.8627451, 0.8745098, 0.88235295, 0.8980392,...\n",
       "4        0  Training  [[0.2784314, 0.30980393, 0.3647059, 0.42352942..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan informasi dataframe setelah normalisasi\n",
    "df_combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.00390619, 0.00390619, 0.00390619, 0.003906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.00236832, 0.002475971, 0.002675894, 0.0029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.00092272204, 0.0012302961, 0.0016916571, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.0032602844, 0.0031372549, 0.0029680892, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.0013225683, 0.0013071896, 0.0012610535, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion       usage                                     resized_pixels\n",
       "0        0  PublicTest  [[0.00390619, 0.00390619, 0.00390619, 0.003906...\n",
       "1        1  PublicTest  [[0.00236832, 0.002475971, 0.002675894, 0.0029...\n",
       "2        4  PublicTest  [[0.00092272204, 0.0012302961, 0.0016916571, 0...\n",
       "3        6  PublicTest  [[0.0032602844, 0.0031372549, 0.0029680892, 0....\n",
       "4        3  PublicTest  [[0.0013225683, 0.0013071896, 0.0012610535, 0...."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan informasi dataframe setelah normalisasi\n",
    "df_public_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6104 entries, 0 to 6103\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   emotion         6104 non-null   int64 \n",
      " 1   usage           3052 non-null   object\n",
      " 2   resized_pixels  6104 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_combined_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERCOBAAN MODEL II DENGAN SIMPAN LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocess lbp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def lbp_transform(image, P=24, R=3):\n",
    "    \"\"\"\n",
    "    Apply circular LBP to the input image after converting to integer type.\n",
    "\n",
    "    :param image: A PyTorch tensor of shape [1, H, W], where H and W are height and width.\n",
    "    :param P: Number of circularly symmetric neighbor set points.\n",
    "    :param R: Radius of circle.\n",
    "    :return: LBP-transformed image as a PyTorch tensor of shape [1, H, W].\n",
    "    \"\"\"\n",
    "    # Convert the PyTorch tensor to a NumPy array\n",
    "    image_np = image.squeeze(0).cpu().numpy()  # Remove channel dimension and convert to NumPy\n",
    "\n",
    "    # Scale the floating-point image to the [0, 255] range and convert to uint8\n",
    "    image_np_int = (image_np * 255).astype(np.uint8)\n",
    "    \n",
    "    # Apply circular LBP using scikit-image\n",
    "    lbp_image = local_binary_pattern(image_np_int, P=P, R=R, method='uniform')\n",
    "    \n",
    "    # Normalize the LBP output (handle cases where min equals max)\n",
    "    lbp_min = lbp_image.min()\n",
    "    lbp_max = lbp_image.max()\n",
    "    \n",
    "    if lbp_min != lbp_max:\n",
    "        lbp_image = (lbp_image - lbp_min) / (lbp_max - lbp_min)  # Normalize to [0, 1]\n",
    "    else:\n",
    "        lbp_image = lbp_image - lbp_min  # Set all values to 0 if min equals max (no variation)\n",
    "    \n",
    "    # Convert back to PyTorch tensor\n",
    "    lbp_tensor = torch.tensor(lbp_image, dtype=torch.float32, device=image.device).unsqueeze(0)  # Add channel dimension back\n",
    "    \n",
    "    return lbp_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "def lbp_preprocess_and_save(df, save_path, P=24, R=3):\n",
    "    \"\"\"\n",
    "    Apply LBP transformation to images in a DataFrame and save the processed data.\n",
    "\n",
    "    :param df: A DataFrame containing 'resized_pixels' column with image data.\n",
    "    :param save_path: Path to save the processed LBP features.\n",
    "    :param P: Number of circularly symmetric neighbor set points for LBP.\n",
    "    :param R: Radius of circle for LBP.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    # Initialize tqdm progress bar\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing LBP\", ncols=100):\n",
    "        # Extract image from 'resized_pixels' and convert to PyTorch tensor\n",
    "        image = torch.tensor(row['resized_pixels'], dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "        # Apply the LBP transform\n",
    "        lbp_image = lbp_transform(image, P=P, R=R)\n",
    "\n",
    "        # Convert the LBP image back to NumPy array and store it\n",
    "        processed_data.append(lbp_image.squeeze(0).cpu().numpy())  # Remove channel dimension\n",
    "    \n",
    "    # Save the processed data as a NumPy file\n",
    "    np.save(save_path, np.array(processed_data))\n",
    "    print(f\"LBP features saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LBP: 100%|██████████████████████████████████████████| 3589/3589 [00:20<00:00, 172.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBP features saved to df_public_test\n"
     ]
    }
   ],
   "source": [
    "lbp_preprocess_and_save(df_public_test, \"df_public_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class DualInputDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, original_images_df, lbp_data_path):\n",
    "        self.original_images = original_images_df['resized_pixels'].values  # Assuming 'resized_pixels' contains the images\n",
    "        self.labels = original_images_df['emotion'].values  # Assuming 'emotion' contains the labels\n",
    "        self.lbp_data = np.load(lbp_data_path, allow_pickle=True)  # Load the LBP features from npy\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.original_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load original image for ResNet-CBAM branch\n",
    "        original_image = torch.tensor(self.original_images[idx]).float()  # Convert image to tensor\n",
    "        original_image = original_image.unsqueeze(0)  # Add channel dimension if needed (e.g., for grayscale)\n",
    "        \n",
    "        # Load preprocessed LBP features for LBP branch\n",
    "        lbp_image = torch.tensor(self.lbp_data[idx]).float()  # Convert LBP features to tensor\n",
    "        \n",
    "        # Load label\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        \n",
    "        return original_image, lbp_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DualInputDataset(df_combined_train, 'df_combined_train.npy')\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DualInputDataset(df_public_test, 'df_public_test.npy')\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: torch.Size([64, 1, 100, 100])\n",
      "LBP image shape: torch.Size([64, 1, 100, 100])\n",
      "Label shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Ambil satu batch dari train_loader\n",
    "for original_image, lbp_image, label in train_loader:\n",
    "    lbp_image = lbp_image.unsqueeze(1)  # Menambahkan channel axis, sehingga shape menjadi [64, 1, 100, 100]\n",
    "\n",
    "    print(f\"Original image shape: {original_image.shape}\")  # Dimensi dari gambar asli (untuk ResNet-CBAM)\n",
    "    print(f\"LBP image shape: {lbp_image.shape}\")  # Dimensi dari hasil ekstraksi LBP\n",
    "    print(f\"Label shape: {label.shape}\")  # Dimensi dari label\n",
    "    \n",
    "    # Hentikan loop setelah satu batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Channel Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "# Spatial Attention Module\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), \"kernel size must be 3 or 7\"\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "# CBAM Block\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ca(x) * x\n",
    "        out = self.sa(out) * out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18_CBAM_7Classes(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CBAM(\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CBAM(\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CBAM(\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CBAM(\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet18 model\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# Modify the ResNet18 model by adding CBAM after conv2 to conv5\n",
    "class ResNet18_CBAM_7Classes(nn.Module):\n",
    "    def __init__(self, original_model, num_classes=7):\n",
    "        super(ResNet18_CBAM_7Classes, self).__init__()\n",
    "        \n",
    "        # Take the original model's layers\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "        self.bn1 = original_model.bn1\n",
    "        self.relu = original_model.relu\n",
    "        self.maxpool = original_model.maxpool\n",
    "        \n",
    "        # Add CBAM after each convolutional block\n",
    "        self.layer1 = nn.Sequential(\n",
    "            original_model.layer1,\n",
    "            CBAM(64)  # After conv2\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            original_model.layer2,\n",
    "            CBAM(128)  # After conv3\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            original_model.layer3,\n",
    "            CBAM(256)  # After conv4\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            original_model.layer4,\n",
    "            CBAM(512)  # After conv5\n",
    "        )\n",
    "        \n",
    "        # Original avgpool layer\n",
    "        self.avgpool = original_model.avgpool\n",
    "        \n",
    "        # Modify the FC layer to output 7 classes\n",
    "        self.fc = nn.Linear(512, 512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the modified network\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create the modified ResNet18 with CBAM for 7 classes\n",
    "model = ResNet18_CBAM_7Classes(model, num_classes=7)\n",
    "\n",
    "\n",
    "print(model.eval())  # Seharusnya [1, 7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCL_Net(\n",
      "  (resnet_cbam): ResNet18_CBAM_7Classes(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): CBAM(\n",
      "        (ca): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): CBAM(\n",
      "        (ca): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): CBAM(\n",
      "        (ca): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): CBAM(\n",
      "        (ca): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (fc_resnet): Linear(in_features=512, out_features=7, bias=True)\n",
      "  (pool_lbp): AdaptiveAvgPool2d(output_size=(16, 16))\n",
      "  (fc_lbp): Linear(in_features=256, out_features=7, bias=True)\n",
      "  (fc_fusion): Linear(in_features=14, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torchvision.models import resnet18 \n",
    "\n",
    "class RCL_Net(nn.Module): \n",
    "    def __init__(self, original_model, num_classes=7): \n",
    "        super(RCL_Net, self).__init__() \n",
    "         \n",
    "        # ResNet-CBAM branch (global feature extraction) \n",
    "        self.resnet_cbam = ResNet18_CBAM_7Classes(original_model, num_classes) \n",
    "         \n",
    "        # FC1 untuk ResNet-CBAM branch (input 512 → output 7)\n",
    "        self.fc_resnet = nn.Linear(512, 7)  \n",
    "         \n",
    "        # LBP branch - tambahkan layer pooling untuk mengurangi dimensi\n",
    "        self.pool_lbp = nn.AdaptiveAvgPool2d((16, 16))  # Mengurangi dimensi dari [100, 100] ke [16, 16]\n",
    "        self.fc_lbp = nn.Linear(16 * 16, 7)  # FC2: setelah pooling jadi [batch_size, 16*16], diubah ke 7\n",
    "         \n",
    "        # FC3 setelah concatenation (input 14 → output 7)\n",
    "        self.fc_fusion = nn.Linear(14, num_classes)  \n",
    "         \n",
    "    def forward(self, x_resnet, lbp_x): \n",
    "        # print(f\"LBP input shape: {lbp_x.shape}\")\n",
    "        \n",
    "        # ResNet-CBAM branch\n",
    "        x_resnet = self.resnet_cbam(x_resnet)\n",
    "        # print(f\"ResNet output shape: {x_resnet.shape}\")\n",
    "        x_resnet = F.sigmoid(self.fc_resnet(x_resnet))\n",
    "        \n",
    "        # LBP branch\n",
    "        lbp_x = self.pool_lbp(lbp_x)  # Pooling untuk mengurangi dimensi\n",
    "        lbp_x = lbp_x.view(lbp_x.size(0), -1)  # Flatten\n",
    "        # print(f\"LBP flattened shape: {lbp_x.shape}\")\n",
    "        lbp_x = F.sigmoid(self.fc_lbp(lbp_x))\n",
    "        \n",
    "        # print(f\"Final shapes - ResNet: {x_resnet.shape}, LBP: {lbp_x.shape}\")\n",
    "\n",
    "        # Concatenate output dari FC1 dan FC2\n",
    "        fused = torch.cat((x_resnet, lbp_x), dim=1)  # Shape: [batch_size, 14] (7+7)\n",
    " \n",
    "        # FC3 dengan sigmoid activation diikuti softmax untuk klasifikasi\n",
    "        fused = F.sigmoid(self.fc_fusion(fused))  # 14 → 7\n",
    "        output = F.softmax(fused, dim=1)  # Menambahkan softmax untuk klasifikasi final\n",
    "         \n",
    "        return output \n",
    "\n",
    "# Instantiate model\n",
    "original_model = resnet18(pretrained=True) \n",
    "model = RCL_Net(original_model, num_classes=7) \n",
    " \n",
    "print(model.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    \"\"\"Mixup data.\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, \n",
    "                      num_epochs=300,\n",
    "                      lr=0.001,  # Learning rate yang lebih kecil\n",
    "                      momentum=0.1,  # Momentum yang lebih besar\n",
    "                      weight_decay=0.0001,\n",
    "                      max_early_stop=30,\n",
    "                      save_path='./checkpoints',\n",
    "                      resume=False):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = torch.device(\"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Tambahkan learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                    factor=0.1, patience=5, \n",
    "                                                    verbose=True)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    start_epoch = 0\n",
    "    early_stop_count = 0\n",
    "\n",
    "    # Resume dari checkpoint jika ada\n",
    "    if resume and os.path.exists(os.path.join(save_path, 'best_model.pth')):\n",
    "        checkpoint = torch.load(os.path.join(save_path, 'best_model.pth'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_val_acc = checkpoint['best_val_acc']\n",
    "        print(f\"Resuming training from epoch {start_epoch + 1} with best validation accuracy {best_val_acc:.4f}\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Training progress bar\n",
    "        train_progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\", leave=True)\n",
    "        \n",
    "        for original_image, lbp_image, labels in train_progress_bar:\n",
    "            original_image, lbp_image, labels = original_image.to(device), lbp_image.to(device), labels.to(device)\n",
    "            outputs = model(original_image, lbp_image)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass dengan gradient clipping\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Perhitungan metrik training\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_acc = correct / total\n",
    "            train_progress_bar.set_postfix(acc=f\"{train_acc:.3f}\", loss=f\"{loss.item():.3f}\")\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        val_progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for original_image, lbp_image, labels in val_progress_bar:\n",
    "                original_image, lbp_image, labels = original_image.to(device), lbp_image.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(original_image, lbp_image)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Simpan predictions dan labels untuk metrik\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Hitung metrik validasi\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Hitung precision, recall, dan F1 score\n",
    "        precision = precision_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"\\nEpoch [{epoch + 1}/{num_epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, hitung : {correct}/{total}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "        print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\\n\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_checkpoint_path = os.path.join(save_path, 'best_model.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1\n",
    "            }, best_checkpoint_path)\n",
    "            print(f\"Best model saved at epoch {epoch + 1} with validation accuracy {val_acc:.4f}\")\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            print(f\"Early stop count: {early_stop_count}/{max_early_stop}\")\n",
    "        \n",
    "        # Save periodic checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = os.path.join(save_path, f'checkpoint_epoch_{epoch + 1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stop_count >= max_early_stop:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 (Training): 100%|██████████| 96/96 [01:38<00:00,  1.03s/it, acc=0.143, loss=1.947]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/300]\n",
      "Train Loss: 1.9460, Train Accuracy: 0.1429, hitung : 872/6104\n",
      "Val Loss: 1.9462, Val Accuracy: 0.1819\n",
      "Precision: 0.0260, Recall: 0.1429, F1: 0.0440\n",
      "Current LR: 0.900000\n",
      "\n",
      "Best model saved at epoch 1 with validation accuracy 0.1819\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300 (Training): 100%|██████████| 96/96 [01:17<00:00,  1.23it/s, acc=0.143, loss=1.946]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/300]\n",
      "Train Loss: 1.9459, Train Accuracy: 0.1429, hitung : 872/6104\n",
      "Val Loss: 1.9462, Val Accuracy: 0.1819\n",
      "Precision: 0.0260, Recall: 0.1429, F1: 0.0440\n",
      "Current LR: 0.900000\n",
      "\n",
      "Early stop count: 1/30\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300 (Training): 100%|██████████| 96/96 [01:35<00:00,  1.00it/s, acc=0.143, loss=1.949]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/300]\n",
      "Train Loss: 1.9458, Train Accuracy: 0.1429, hitung : 872/6104\n",
      "Val Loss: 1.9462, Val Accuracy: 0.1819\n",
      "Precision: 0.0260, Recall: 0.1429, F1: 0.0440\n",
      "Current LR: 0.900000\n",
      "\n",
      "Early stop count: 2/30\n",
      "Epoch 4/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300 (Training): 100%|██████████| 96/96 [01:27<00:00,  1.10it/s, acc=0.143, loss=1.943]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/300]\n",
      "Train Loss: 1.9453, Train Accuracy: 0.1432, hitung : 874/6104\n",
      "Val Loss: 1.9462, Val Accuracy: 0.1819\n",
      "Precision: 0.0260, Recall: 0.1429, F1: 0.0440\n",
      "Current LR: 0.900000\n",
      "\n",
      "Early stop count: 3/30\n",
      "Epoch 5/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300 (Training): 100%|██████████| 96/96 [01:24<00:00,  1.14it/s, acc=0.209, loss=1.941]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/300]\n",
      "Train Loss: 1.9435, Train Accuracy: 0.2089, hitung : 1275/6104\n",
      "Val Loss: 1.9462, Val Accuracy: 0.1819\n",
      "Precision: 0.0260, Recall: 0.1429, F1: 0.0440\n",
      "Current LR: 0.900000\n",
      "\n",
      "Early stop count: 4/30\n",
      "Epoch 6/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300 (Training): 100%|██████████| 96/96 [01:29<00:00,  1.07it/s, acc=0.287, loss=1.931]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/300]\n",
      "Train Loss: 1.9392, Train Accuracy: 0.2870, hitung : 1752/6104\n",
      "Val Loss: 1.9468, Val Accuracy: 0.1819\n",
      "Precision: 0.0260, Recall: 0.1429, F1: 0.0440\n",
      "Current LR: 0.900000\n",
      "\n",
      "Early stop count: 5/30\n",
      "Epoch 7/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300 (Training): 100%|██████████| 96/96 [01:14<00:00,  1.28it/s, acc=0.261, loss=1.930]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/300]\n",
      "Train Loss: 1.9340, Train Accuracy: 0.2608, hitung : 1592/6104\n",
      "Val Loss: 1.9475, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.090000\n",
      "\n",
      "Early stop count: 6/30\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300 (Training): 100%|██████████| 96/96 [01:11<00:00,  1.35it/s, acc=0.268, loss=1.923]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/300]\n",
      "Train Loss: 1.9306, Train Accuracy: 0.2683, hitung : 1638/6104\n",
      "Val Loss: 1.9480, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.090000\n",
      "\n",
      "Early stop count: 7/30\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300 (Training): 100%|██████████| 96/96 [01:10<00:00,  1.37it/s, acc=0.270, loss=1.934]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/300]\n",
      "Train Loss: 1.9299, Train Accuracy: 0.2697, hitung : 1646/6104\n",
      "Val Loss: 1.9481, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.090000\n",
      "\n",
      "Early stop count: 8/30\n",
      "Epoch 10/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300 (Training): 100%|██████████| 96/96 [01:12<00:00,  1.32it/s, acc=0.271, loss=1.922]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/300]\n",
      "Train Loss: 1.9292, Train Accuracy: 0.2713, hitung : 1656/6104\n",
      "Val Loss: 1.9482, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.090000\n",
      "\n",
      "Early stop count: 9/30\n",
      "Checkpoint saved at epoch 10\n",
      "Epoch 11/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300 (Training): 100%|██████████| 96/96 [01:10<00:00,  1.36it/s, acc=0.272, loss=1.922]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [11/300]\n",
      "Train Loss: 1.9285, Train Accuracy: 0.2718, hitung : 1659/6104\n",
      "Val Loss: 1.9482, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.090000\n",
      "\n",
      "Early stop count: 10/30\n",
      "Epoch 12/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300 (Training): 100%|██████████| 96/96 [01:10<00:00,  1.36it/s, acc=0.273, loss=1.928]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [12/300]\n",
      "Train Loss: 1.9280, Train Accuracy: 0.2726, hitung : 1664/6104\n",
      "Val Loss: 1.9482, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.090000\n",
      "\n",
      "Early stop count: 11/30\n",
      "Epoch 13/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300 (Training): 100%|██████████| 96/96 [01:09<00:00,  1.39it/s, acc=0.274, loss=1.931]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [13/300]\n",
      "Train Loss: 1.9275, Train Accuracy: 0.2739, hitung : 1672/6104\n",
      "Val Loss: 1.9484, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.009000\n",
      "\n",
      "Early stop count: 12/30\n",
      "Epoch 14/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300 (Training): 100%|██████████| 96/96 [01:09<00:00,  1.39it/s, acc=0.274, loss=1.928]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [14/300]\n",
      "Train Loss: 1.9270, Train Accuracy: 0.2741, hitung : 1673/6104\n",
      "Val Loss: 1.9483, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.009000\n",
      "\n",
      "Early stop count: 13/30\n",
      "Epoch 15/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300 (Training): 100%|██████████| 96/96 [01:12<00:00,  1.33it/s, acc=0.274, loss=1.916]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [15/300]\n",
      "Train Loss: 1.9269, Train Accuracy: 0.2741, hitung : 1673/6104\n",
      "Val Loss: 1.9483, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.009000\n",
      "\n",
      "Early stop count: 14/30\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300 (Training): 100%|██████████| 96/96 [01:09<00:00,  1.38it/s, acc=0.274, loss=1.934]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [16/300]\n",
      "Train Loss: 1.9269, Train Accuracy: 0.2739, hitung : 1672/6104\n",
      "Val Loss: 1.9484, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.009000\n",
      "\n",
      "Early stop count: 15/30\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300 (Training): 100%|██████████| 96/96 [01:12<00:00,  1.33it/s, acc=0.274, loss=1.931]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [17/300]\n",
      "Train Loss: 1.9268, Train Accuracy: 0.2736, hitung : 1670/6104\n",
      "Val Loss: 1.9483, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.009000\n",
      "\n",
      "Early stop count: 16/30\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300 (Training): 100%|██████████| 96/96 [01:10<00:00,  1.35it/s, acc=0.275, loss=1.916]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [18/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2747, hitung : 1677/6104\n",
      "Val Loss: 1.9485, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.009000\n",
      "\n",
      "Early stop count: 17/30\n",
      "Epoch 19/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300 (Training): 100%|██████████| 96/96 [01:11<00:00,  1.34it/s, acc=0.275, loss=1.930]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [19/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2746, hitung : 1676/6104\n",
      "Val Loss: 1.9484, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000900\n",
      "\n",
      "Early stop count: 18/30\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/300 (Training): 100%|██████████| 96/96 [01:11<00:00,  1.34it/s, acc=0.274, loss=1.924]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [20/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2744, hitung : 1675/6104\n",
      "Val Loss: 1.9483, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000900\n",
      "\n",
      "Early stop count: 19/30\n",
      "Checkpoint saved at epoch 20\n",
      "Epoch 21/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/300 (Training): 100%|██████████| 96/96 [01:14<00:00,  1.29it/s, acc=0.274, loss=1.928]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [21/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2744, hitung : 1675/6104\n",
      "Val Loss: 1.9484, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000900\n",
      "\n",
      "Early stop count: 20/30\n",
      "Epoch 22/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/300 (Training): 100%|██████████| 96/96 [01:13<00:00,  1.31it/s, acc=0.275, loss=1.935]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [22/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2747, hitung : 1677/6104\n",
      "Val Loss: 1.9484, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000900\n",
      "\n",
      "Early stop count: 21/30\n",
      "Epoch 23/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/300 (Training): 100%|██████████| 96/96 [01:12<00:00,  1.33it/s, acc=0.274, loss=1.931]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [23/300]\n",
      "Train Loss: 1.9267, Train Accuracy: 0.2738, hitung : 1671/6104\n",
      "Val Loss: 1.9485, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000900\n",
      "\n",
      "Early stop count: 22/30\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/300 (Training): 100%|██████████| 96/96 [01:10<00:00,  1.37it/s, acc=0.274, loss=1.939]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [24/300]\n",
      "Train Loss: 1.9267, Train Accuracy: 0.2742, hitung : 1674/6104\n",
      "Val Loss: 1.9486, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000900\n",
      "\n",
      "Early stop count: 23/30\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/300 (Training): 100%|██████████| 96/96 [01:15<00:00,  1.27it/s, acc=0.274, loss=1.941]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [25/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2738, hitung : 1671/6104\n",
      "Val Loss: 1.9485, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000090\n",
      "\n",
      "Early stop count: 24/30\n",
      "Epoch 26/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/300 (Training): 100%|██████████| 96/96 [01:11<00:00,  1.34it/s, acc=0.274, loss=1.922]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [26/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2744, hitung : 1675/6104\n",
      "Val Loss: 1.9482, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000090\n",
      "\n",
      "Early stop count: 25/30\n",
      "Epoch 27/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/300 (Training): 100%|██████████| 96/96 [01:11<00:00,  1.35it/s, acc=0.274, loss=1.924]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [27/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2741, hitung : 1673/6104\n",
      "Val Loss: 1.9483, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000090\n",
      "\n",
      "Early stop count: 26/30\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/300 (Training): 100%|██████████| 96/96 [01:10<00:00,  1.36it/s, acc=0.274, loss=1.924]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [28/300]\n",
      "Train Loss: 1.9265, Train Accuracy: 0.2744, hitung : 1675/6104\n",
      "Val Loss: 1.9486, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000090\n",
      "\n",
      "Early stop count: 27/30\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/300 (Training): 100%|██████████| 96/96 [01:11<00:00,  1.35it/s, acc=0.274, loss=1.922]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [29/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2742, hitung : 1674/6104\n",
      "Val Loss: 1.9485, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000090\n",
      "\n",
      "Early stop count: 28/30\n",
      "Epoch 30/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/300 (Training): 100%|██████████| 96/96 [01:10<00:00,  1.36it/s, acc=0.275, loss=1.927]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [30/300]\n",
      "Train Loss: 1.9265, Train Accuracy: 0.2747, hitung : 1677/6104\n",
      "Val Loss: 1.9486, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000090\n",
      "\n",
      "Early stop count: 29/30\n",
      "Checkpoint saved at epoch 30\n",
      "Epoch 31/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/300 (Training): 100%|██████████| 96/96 [01:09<00:00,  1.38it/s, acc=0.275, loss=1.927]\n",
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [31/300]\n",
      "Train Loss: 1.9266, Train Accuracy: 0.2747, hitung : 1677/6104\n",
      "Val Loss: 1.9486, Val Accuracy: 0.0156\n",
      "Precision: 0.0022, Recall: 0.1429, F1: 0.0044\n",
      "Current LR: 0.000009\n",
      "\n",
      "Early stop count: 30/30\n",
      "Training stopped early at epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Buat directory untuk checkpoints\n",
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "\n",
    "# Training\n",
    "model = train_and_evaluate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=300,\n",
    "    lr=0.9,\n",
    "    momentum=0.1,\n",
    "    weight_decay=0.0001,\n",
    "    max_early_stop=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PERTAMA TANPA SIMPAN LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konversi DataFrame ke Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image = torch.tensor(self.dataframe['resized_pixels'].iloc[idx], dtype=torch.float32).view(1, 100, 100)  # Jika gambar 100x100\n",
    "        # label = torch.tensor(self.dataframe['emotion'].iloc[idx], dtype=torch.long)\n",
    "        image = torch.tensor(self.dataframe['resized_pixels'].iloc[idx], dtype=torch.float32).unsqueeze(0)  # Sudah 100x100, hanya tambah channel dimension\n",
    "        label = torch.tensor(self.dataframe['emotion'].iloc[idx], dtype=torch.long)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi dataset\n",
    "train_dataset = EmotionDataset(df_combined_train)\n",
    "test_dataset = EmotionDataset(df_public_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Inisialisasi DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Bersihkan cache CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Channel Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "# Spatial Attention Module\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), \"kernel size must be 3 or 7\"\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "# CBAM Block\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ca(x) * x\n",
    "        out = self.sa(out) * out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18_CBAM_7Classes(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CBAM(\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CBAM(\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CBAM(\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CBAM(\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet18 model\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# Modify the ResNet18 model by adding CBAM after conv2 to conv5\n",
    "class ResNet18_CBAM_7Classes(nn.Module):\n",
    "    def __init__(self, original_model, num_classes=7):\n",
    "        super(ResNet18_CBAM_7Classes, self).__init__()\n",
    "        \n",
    "        # Take the original model's layers\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "        self.bn1 = original_model.bn1\n",
    "        self.relu = original_model.relu\n",
    "        self.maxpool = original_model.maxpool\n",
    "        \n",
    "        # Add CBAM after each convolutional block\n",
    "        self.layer1 = nn.Sequential(\n",
    "            original_model.layer1,\n",
    "            CBAM(64)  # After conv2\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            original_model.layer2,\n",
    "            CBAM(128)  # After conv3\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            original_model.layer3,\n",
    "            CBAM(256)  # After conv4\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            original_model.layer4,\n",
    "            CBAM(512)  # After conv5\n",
    "        )\n",
    "        \n",
    "        # Original avgpool layer\n",
    "        self.avgpool = original_model.avgpool\n",
    "        \n",
    "        # Modify the FC layer to output 7 classes\n",
    "        self.fc = nn.Linear(512, 512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the modified network\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create the modified ResNet18 with CBAM for 7 classes\n",
    "model = ResNet18_CBAM_7Classes(model, num_classes=7)\n",
    "\n",
    "\n",
    "print(model.eval())  # Seharusnya [1, 7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def lbp_transform(image):\n",
    "    \"\"\"\n",
    "    Apply the LBP operation on the input image (assumed to be grayscale).\n",
    "    The image tensor should be of shape [batch_size, 1, height, width].\n",
    "    \n",
    "    :param image: Input image tensor (on GPU)\n",
    "    :return: LBP transformed image tensor\n",
    "    \"\"\"\n",
    "    # Define the LBP kernel (neighboring comparison)\n",
    "    lbp_kernel = torch.tensor([[[[ 1,  1,  1],\n",
    "                                 [ 1,  0, -1],\n",
    "                                 [-1, -1, -1]]],\n",
    "                               [[[ 1,  1,  1],\n",
    "                                 [ 1,  0, -1],\n",
    "                                 [-1, -1, -1]]]], dtype=torch.float32, device=image.device)\n",
    "\n",
    "    # Apply the kernel using convolution (with padding to keep the same size)\n",
    "    lbp_image = F.conv2d(image, lbp_kernel, padding=1)\n",
    "\n",
    "    # Convert the convolution result into binary (using sign function)\n",
    "    lbp_image = (lbp_image > 0).float()\n",
    "\n",
    "    return lbp_image\n",
    "\n",
    "# Example of using the function on GPU\n",
    "# Assume `input_image` is a grayscale image tensor of shape [batch_size, 1, height, width]\n",
    "input_image = torch.randn((8, 1, 48, 48), device='cuda')  # Example tensor on GPU\n",
    "lbp_output = lbp_transform(input_image)\n",
    "\n",
    "print(lbp_output.shape)  # Should be the same as input shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCL_Net(\n",
      "  (resnet_cbam): ResNet18_CBAM_7Classes(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): CBAM(\n",
      "        (ca): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): CBAM(\n",
      "        (ca): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): CBAM(\n",
      "        (ca): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): CBAM(\n",
      "        (ca): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (sa): SpatialAttention(\n",
      "          (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (conv1_lbp): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_lbp): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_lbp): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool_lbp): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc_lbp): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc_resnet): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc_fusion): Linear(in_features=512, out_features=14, bias=True)\n",
      "  (fc_output): Linear(in_features=14, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# LBP feature extraction function (you can implement this with OpenCV or any other method)\n",
    "# def lbp_transform(image):\n",
    "#     # Placeholder: Implement LBP transformation here\n",
    "#     # For now, assume it returns a tensor of the same size as the input image\n",
    "#     return image  # This should be the LBP transformed image\n",
    "\n",
    "# Define the modified model class with the LBP branch\n",
    "class RCL_Net(nn.Module):\n",
    "    def __init__(self, original_model, num_classes=7):\n",
    "        super(RCL_Net, self).__init__()\n",
    "        \n",
    "        # ResNet-CBAM branch (global feature extraction)\n",
    "        self.resnet_cbam = ResNet18_CBAM_7Classes(original_model, num_classes)\n",
    "        \n",
    "        # LBP branch (local feature extraction)\n",
    "        self.conv1_lbp = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1)  # Input: 2 channels\n",
    "        self.conv2_lbp = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_lbp = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_lbp = nn.AdaptiveAvgPool2d((1, 1))  # Pooling to [batch_size, 256, 1, 1]\n",
    "        \n",
    "        # Fully connected layer for LBP branch (FC2)\n",
    "        self.fc_lbp = nn.Linear(256, 256)\n",
    "        \n",
    "        # Fully connected layers for ResNet-CBAM branch (FC1)\n",
    "        self.fc_resnet = nn.Linear(512, 256)  # FC1 for ResNet-CBAM\n",
    "        \n",
    "        # Fully connected layers after feature fusion (FC3)\n",
    "        self.fc_fusion = nn.Linear(256 + 256, 14)  # FC3\n",
    "        self.fc_output = nn.Linear(14, num_classes)  # Final classification\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through ResNet-CBAM branch (global features)\n",
    "        x_resnet = self.resnet_cbam(x)  # Output: [batch_size, 512]\n",
    "        x_resnet = F.relu(self.fc_resnet(x_resnet))  # Shape: [batch_size, 256] (FC1)\n",
    "\n",
    "        # LBP branch (local features)\n",
    "        lbp_image = lbp_transform(x)  # Apply LBP transformation\n",
    "        lbp_x = F.relu(self.conv1_lbp(lbp_image))\n",
    "        lbp_x = F.relu(self.conv2_lbp(lbp_x))\n",
    "        lbp_x = F.relu(self.conv3_lbp(lbp_x))\n",
    "        lbp_x = self.pool_lbp(lbp_x)  # Pool to [batch_size, 256, 1, 1]\n",
    "        lbp_x = lbp_x.view(lbp_x.size(0), -1)  # Flatten to [batch_size, 256]\n",
    "        lbp_x = F.relu(self.fc_lbp(lbp_x))  # Shape: [batch_size, 256] (FC2)\n",
    "\n",
    "        # Concatenate ResNet-CBAM and LBP feature vectors\n",
    "        fused = torch.cat((x_resnet, lbp_x), dim=1)  # Shape: [batch_size, 256 + 256]\n",
    "\n",
    "        # Pass through fusion fully connected layers (FC3)\n",
    "        fused = F.sigmoid(self.fc_fusion(fused))  # Apply sigmoid activation (σ)\n",
    "        \n",
    "        # Final classification output\n",
    "        output = self.fc_output(fused)  # Output: [batch_size, num_classes]\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Instantiate the model with ResNet18 backbone\n",
    "original_model = resnet18(pretrained=True)\n",
    "model = RCL_Net(original_model, num_classes=7)\n",
    "\n",
    "print(model.eval())  # To check the model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    \"\"\"Mixup data.\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, \n",
    "                      num_epochs=300,\n",
    "                      lr=0.001,  # Learning rate yang lebih kecil\n",
    "                      momentum=0.1,  # Momentum yang lebih besar\n",
    "                      weight_decay=0.0001,\n",
    "                      max_early_stop=30,\n",
    "                      save_path='./checkpoints',\n",
    "                      resume=False):\n",
    "    \n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Tambahkan learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                    factor=0.1, patience=5, \n",
    "                                                    verbose=True)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    start_epoch = 0\n",
    "    early_stop_count = 0\n",
    "\n",
    "    # Resume dari checkpoint jika ada\n",
    "    if resume and os.path.exists(os.path.join(save_path, 'best_model.pth')):\n",
    "        checkpoint = torch.load(os.path.join(save_path, 'best_model.pth'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_val_acc = checkpoint['best_val_acc']\n",
    "        print(f\"Resuming training from epoch {start_epoch + 1} with best validation accuracy {best_val_acc:.4f}\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Training progress bar\n",
    "        train_progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\", leave=True)\n",
    "        \n",
    "        for inputs, labels in train_progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass dengan gradient clipping\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Perhitungan metrik training\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_acc = correct / total\n",
    "            train_progress_bar.set_postfix(acc=f\"{train_acc:.3f}\", loss=f\"{loss.item():.3f}\")\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        val_progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_progress_bar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Simpan predictions dan labels untuk metrik\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Hitung metrik validasi\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Hitung precision, recall, dan F1 score\n",
    "        precision = precision_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"\\nEpoch [{epoch + 1}/{num_epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, hitung : {correct}/{total}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "        print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\\n\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_checkpoint_path = os.path.join(save_path, 'best_model.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1\n",
    "            }, best_checkpoint_path)\n",
    "            print(f\"Best model saved at epoch {epoch + 1} with validation accuracy {val_acc:.4f}\")\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            print(f\"Early stop count: {early_stop_count}/{max_early_stop}\")\n",
    "        \n",
    "        # Save periodic checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = os.path.join(save_path, f'checkpoint_epoch_{epoch + 1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stop_count >= max_early_stop:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 (Training):   0%|          | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_early_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[50], line 55\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, val_loader, num_epochs, lr, momentum, weight_decay, max_early_stop, save_path, resume)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Training progress bar\u001b[39;00m\n\u001b[0;32m     53\u001b[0m train_progress_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Training)\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_progress_bar:\n\u001b[0;32m     56\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Buat directory untuk checkpoints\n",
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "\n",
    "# Training\n",
    "model = train_and_evaluate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=300,\n",
    "    lr=0.9,\n",
    "    momentum=0.1,\n",
    "    weight_decay=0.0001,\n",
    "    max_early_stop=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
