{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analys The Problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously on papper \"Facial Expression Recognition Methods in the Wild Based on Fusion Feature of Attention Mechanism and LBP (MDPI Sensors 2023 Q2)\" authors used a model called ResNet-50 combined CBAM and LBP.\n",
    "\n",
    "The accuracy took:\n",
    "- 99.66% on CK+\n",
    "- 74.23% on FER-2013\n",
    "- 89.50 on FER-PLUS \n",
    "- 88.20 on RAF-DB\n",
    "\n",
    "**The problem: What if I change the variant of LBP in this method, does it increase the accuracy spesifically for FER-2013 dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **About Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The paper used 4 dataset include CK+(59 images), FER-2013 (35,887 images), FER-PLUS(31.412 images), RAF-DB (29,672 images)\n",
    "- CK+ is a controlled dataset and the 3 others datasets are uncontrolled datasets\n",
    "- Controlled dataset has good lightning and pose but uncontrolled datasets got a random of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ResNet-18 + CBAM**\n",
    "\n",
    "    1. Architecture of ResNet-18:\n",
    "    \n",
    "        <img src=\"../src/Structure-of-a-ResNet-18-architecture.png\" alt=\"Windowing of Feature in Faces\" width=\"350\" height=\"250\">\n",
    "\n",
    "    2. CBAM Architecture:\n",
    "\n",
    "        <img src=\"../src/cbam.png\" alt=\"Windowing of Feature in Faces\" width=\"600\" height=\"100\">\n",
    "\n",
    "    3. Authors combine the CBAM module into each block of the ResNet-18 architecture,\n",
    "    \n",
    "        Before and After implement the CBAM module:\n",
    "\n",
    "        <img src=\"../src/oriblock.png\" alt=\"Windowing of Feature in Faces\" width=\"150\" height=\"200\">\n",
    "        <img src=\"../src/blocknCbam.png\" alt=\"Windowing of Feature in Faces\" width=\"150\" height=\"200\">\n",
    "\n",
    "- **Local Binary Patterns (LBP)**\n",
    "\n",
    "    LBP is one of the most generally used texture pattern descriptors for examining local grain features and is regarded as one of the best methods for texture processing, which is widely employed in image processing.\n",
    "\n",
    "- **RCL-Net Model**\n",
    "\n",
    "    After combining all the method such as LBP and ResNet-CBAM, this architecture called by **RCL-Net Model**,\n",
    "\n",
    "    <img src=\"../src/rcl-net.png\" alt=\"Windowing of Feature in Faces\" width=\"700\" height=\"200\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In planning, switching LBP method in previous architecture with the newest or other variant LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for augmen:\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# for mixup augmen:\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# mixup from train.py file\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# LBP\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Bersihkan cache CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA LOADING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca file CSV\n",
    "# file_path_train = 'D:/Ando File 4 Kuliah/A SKRIPSI/RISETku/KERJA/DATA/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv'  # Ganti dengan lokasi file kamu\n",
    "# df_train = pd.read_csv(file_path_train)\n",
    "\n",
    "# file_path_test = 'D:/Ando File 4 Kuliah/A SKRIPSI/RISETku/KERJA/DATA/challenges-in-representation-learning-facial-expression-recognition-challenge/test.csv'  # Ganti dengan lokasi file kamu\n",
    "# df_test = pd.read_csv(file_path_test)\n",
    "\n",
    "file_path = 'D:/Ando File 4 Kuliah/A SKRIPSI/RISETku/KERJA/DATA/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv'  # Ganti dengan lokasi file kamu\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the data on datatables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     Usage                                             pixels\n",
       "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREPROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resized Image 100 x 100:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define function resized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah string pixel menjadi gambar\n",
    "def convert_to_image(pixels, size=(48, 48), new_size=(100, 100)):\n",
    "    # Ubah string pixel menjadi array\n",
    "    pixel_values = np.array(pixels.split(), dtype=np.uint8)\n",
    "    \n",
    "    # Ubah array 1D menjadi array 2D\n",
    "    image = pixel_values.reshape(size)\n",
    "    \n",
    "    # Buat gambar dari array 2D\n",
    "    img = Image.fromarray(image)\n",
    "    \n",
    "    # Ubah ukuran gambar menggunakan LANCZOS untuk kualitas terbaik\n",
    "    resized_img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processing the resize to all images and saved to new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 35887/35887 [03:45<00:00, 159.20it/s]\n"
     ]
    }
   ],
   "source": [
    "df_resized = pd.DataFrame(columns=['emotion', 'usage', 'resized_pixels']) # DataFrame baru untuk menyimpan gambar yang sudah diproses\n",
    "\n",
    "# Proses setiap baris di DataFrame asli dengan progress bar\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\"):\n",
    "    pixels = row[' pixels']\n",
    "    \n",
    "    # Konversi pixel menjadi gambar dan resize\n",
    "    resized_image = convert_to_image(pixels)\n",
    "    \n",
    "    # Ubah gambar yang diresize menjadi array 1D untuk disimpan dalam DataFrame\n",
    "    resized_image_array = np.array(resized_image).flatten()\n",
    "    \n",
    "    # Buat DataFrame baru untuk baris ini\n",
    "    new_row = pd.DataFrame({\n",
    "        'emotion': [row['emotion']],\n",
    "        'usage': [row[' Usage']],\n",
    "        'resized_pixels': [' '.join(resized_image_array.astype(str))]\n",
    "    })\n",
    "    \n",
    "    # Gabungkan baris baru dengan DataFrame yang sudah ada\n",
    "    df_resized = pd.concat([df_resized, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking info of dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   emotion         35887 non-null  object\n",
      " 1   usage           35887 non-null  object\n",
      " 2   resized_pixels  35887 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_resized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35887</td>\n",
       "      <td>35887</td>\n",
       "      <td>35887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>34034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3</td>\n",
       "      <td>Training</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8989</td>\n",
       "      <td>28709</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        emotion     usage                                     resized_pixels\n",
       "count     35887     35887                                              35887\n",
       "unique        7         3                                              34034\n",
       "top           3  Training  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "freq       8989     28709                                                 12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>69 71 77 84 86 84 80 72 64 59 57 57 57 58 61 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 151 151 149 147 148 152 155 153 148 144 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>230 232 227 205 173 154 153 166 178 175 154 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>23 25 28 34 37 36 32 29 31 32 28 23 20 19 18 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>6 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion     usage                                     resized_pixels\n",
       "0       0  Training  69 71 77 84 86 84 80 72 64 59 57 57 57 58 61 6...\n",
       "1       0  Training  151 151 151 149 147 148 152 155 153 148 144 13...\n",
       "2       2  Training  230 232 227 205 173 154 153 166 178 175 154 13...\n",
       "3       4  Training  23 25 28 34 37 36 32 29 31 32 28 23 20 19 18 2...\n",
       "4       6  Training  6 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking column's names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emotion', 'usage', 'resized_pixels'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resized.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking unique value in \"Usage\" columnns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Training', 'PublicTest', 'PrivateTest'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resized['usage'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating between trai, public, and private test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data yang Usage-nya \"Training\"\n",
    "df_train = df_resized[df_resized['usage'] == 'Training']\n",
    "df_public_test = df_resized[df_resized['usage'] == 'PublicTest']\n",
    "df_private_test = df_resized[df_resized['usage'] == 'PrivateTest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking total of row and column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 3)\n",
      "(3589, 3)\n",
      "(3589, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_public_test.shape)\n",
    "print(df_private_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before Resized 48x48:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ambil data pixels dari baris yang diinginkan\n",
    "row_index = 0  # Ganti dengan indeks baris yang diinginkan\n",
    "pixels = df[' pixels'][row_index]\n",
    "\n",
    "# Ubah string pixel menjadi array 1D\n",
    "pixel_values = np.array(pixels.split(), dtype=np.uint8)\n",
    "\n",
    "# Ubah array 1D menjadi array 2D\n",
    "image = pixel_values.reshape(48, 48)\n",
    "\n",
    "# Tampilkan gambar\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Emotion: {df['emotion'][row_index]}\")\n",
    "plt.axis('off')  # Hilangkan sumbu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After resized 100x100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ambil data pixels dari baris yang diinginkan\n",
    "row_index = 0  # indeks baris yang diinginkan\n",
    "pixels = df_resized['resized_pixels'][row_index]\n",
    "\n",
    "# Ubah string pixel menjadi array 1D\n",
    "pixel_values = np.array(pixels.split(), dtype=np.uint8)\n",
    "\n",
    "# Ubah array 1D menjadi array 2D (100x100)\n",
    "image = pixel_values.reshape(100, 100)\n",
    "\n",
    "# Tampilkan gambar\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Emotion: {df_resized['emotion'][row_index]}\")\n",
    "plt.axis('off')  # Hilangkan sumbu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmantation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define augmentation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi augmentasi\n",
    "def augment_image(image):\n",
    "    # Pipeline augmentasi menggunakan albumentations\n",
    "    transform = A.Compose([\n",
    "        A.RandomCrop(width=90, height=90),         # Random crop ukuran 80x80 dari gambar asli (100x100)\n",
    "        A.HorizontalFlip(p=0.5),                   # Membalik gambar secara horizontal dengan probabilitas 50%\n",
    "        A.Rotate(limit=20, p=0.5),                 # Memutar gambar dengan sudut hingga 20 derajat\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),  # Jitter warna\n",
    "        A.CoarseDropout(max_holes=4, max_height=5, max_width=5, p=0.5),  # Random masking\n",
    "        A.Resize(100, 100),                        # Resize kembali menjadi ukuran 100x100\n",
    "        # A.Normalize(mean=(0.5,), std=(0.5,)),      # Dibuatr normalize 0,1 agar bentuknya kembali semula kalo ini dihilangkan outputnya pecah, gak jadi ini setelah augmentasi\n",
    "        ToTensorV2()                               # Ubah gambar menjadi tensor PyTorch\n",
    "    ])\n",
    "    \n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processing the augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 28709/28709 [03:44<00:00, 127.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# List untuk menyimpan hasil augmentasi\n",
    "augmented_images = []\n",
    "augmented_emotions = []\n",
    "\n",
    "# Proses augmentasi untuk setiap gambar di dataframe asli\n",
    "for i in tqdm(range(len(df_train)), desc=\"Augmenting images\"):\n",
    "    # Ambil gambar dari dataframe dan ubah menjadi array 2D\n",
    "    pixels = np.array(df_train['resized_pixels'][i].split(), dtype=np.uint8).reshape(100, 100)\n",
    "    \n",
    "    # Augmentasi gambar\n",
    "    augmented_image = augment_image(pixels)\n",
    "    \n",
    "    # Ubah tensor augmented_image kembali ke numpy array, lalu ubah jadi string lagi untuk disimpan di dataframe\n",
    "    augmented_image_np = augmented_image.permute(1, 2, 0).numpy().flatten().tolist()  # Ubah ke list 1D\n",
    "    augmented_image_str = ' '.join(map(str, augmented_image_np))  # Ubah list jadi string\n",
    "    \n",
    "    # Simpan gambar yang sudah di-augmentasi dan emosi ke list\n",
    "    augmented_images.append(augmented_image_str)\n",
    "    augmented_emotions.append(df_train['emotion'][i])\n",
    "\n",
    "# Masukkan hasil augmentasi ke dataframe baru\n",
    "augmented_df_train = pd.DataFrame({\n",
    "    'emotion': augmented_emotions,\n",
    "    'resized_pixels': augmented_images\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>87 76 69 64 58 58 63 67 73 82 93 106 117 126 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>127 114 98 92 105 127 141 139 120 92 74 80 96 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>44 50 61 73 80 77 68 64 73 92 107 121 134 148 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>164 167 169 162 147 128 109 94 88 88 85 76 69 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>28 28 28 28 29 27 22 15 9 5 3 2 3 7 12 18 27 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28704</th>\n",
       "      <td>2</td>\n",
       "      <td>70 70 70 69 69 69 69 69 69 69 69 69 69 69 69 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28705</th>\n",
       "      <td>0</td>\n",
       "      <td>85 89 94 96 95 95 95 95 95 96 98 98 99 100 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28706</th>\n",
       "      <td>4</td>\n",
       "      <td>182 186 190 194 197 198 199 198 197 195 192 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>0</td>\n",
       "      <td>143 145 149 153 157 159 162 163 164 166 166 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28708</th>\n",
       "      <td>4</td>\n",
       "      <td>193 195 195 194 193 192 189 186 183 181 180 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28709 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                     resized_pixels\n",
       "0            0  87 76 69 64 58 58 63 67 73 82 93 106 117 126 1...\n",
       "1            0  127 114 98 92 105 127 141 139 120 92 74 80 96 ...\n",
       "2            2  44 50 61 73 80 77 68 64 73 92 107 121 134 148 ...\n",
       "3            4  164 167 169 162 147 128 109 94 88 88 85 76 69 ...\n",
       "4            6  28 28 28 28 29 27 22 15 9 5 3 2 3 7 12 18 27 3...\n",
       "...        ...                                                ...\n",
       "28704        2  70 70 70 69 69 69 69 69 69 69 69 69 69 69 69 6...\n",
       "28705        0  85 89 94 96 95 95 95 95 95 96 98 98 99 100 100...\n",
       "28706        4  182 186 190 194 197 198 199 198 197 195 192 19...\n",
       "28707        0  143 145 149 153 157 159 162 163 164 166 166 16...\n",
       "28708        4  193 195 195 194 193 192 189 186 183 181 180 18...\n",
       "\n",
       "[28709 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize image after augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ambil data pixels dari baris yang diinginkan\n",
    "row_index = 0  # Ganti dengan indeks baris yang diinginkan\n",
    "pixels = augmented_df_train['resized_pixels'][row_index]\n",
    "\n",
    "# Ubah string pixel menjadi array 1D (float)\n",
    "pixel_values = np.array(pixels.split(), dtype=np.float32)\n",
    "\n",
    "# Denormalisasi dari rentang [-1, 1] ke [0, 255]\n",
    "# pixel_values = (pixel_values * 0.5 + 0.5) * 255  # Skala ulang ke [0, 255]\n",
    "\n",
    "# Ubah array 1D menjadi array 2D (100x100)\n",
    "image = pixel_values.reshape(100, 100)\n",
    "\n",
    "# Ubah ke tipe data uint8 agar bisa ditampilkan sebagai gambar\n",
    "image = image.astype(np.uint8)\n",
    "\n",
    "# Tampilkan gambar\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Emotion: {augmented_df_train['emotion'][row_index]}\")\n",
    "plt.axis('off')  # Hilangkan sumbu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Append the new augmentation into original dataframe before the augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data setelah augmentasi: 57418\n",
      "  emotion     usage                                     resized_pixels\n",
      "0       0  Training  69 71 77 84 86 84 80 72 64 59 57 57 57 58 61 6...\n",
      "1       0  Training  151 151 151 149 147 148 152 155 153 148 144 13...\n",
      "2       2  Training  230 232 227 205 173 154 153 166 178 175 154 13...\n",
      "3       4  Training  23 25 28 34 37 36 32 29 31 32 28 23 20 19 18 2...\n",
      "4       6  Training  6 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Gabungkan dataframe asli dengan dataframe augmented\n",
    "combined_df_train = pd.concat([df_train, augmented_df_train], ignore_index=True)\n",
    "\n",
    "# Tampilkan informasi jumlah data\n",
    "print(f\"Jumlah data setelah augmentasi: {len(combined_df_train)}\")\n",
    "\n",
    "# Tampilkan contoh baris dari dataframe gabungan\n",
    "print(combined_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define function normalize pixel to [0,1] dividing by 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk normalisasi nilai piksel\n",
    "def normalize_pixels(pixels):\n",
    "    # Ubah string pixel menjadi array float\n",
    "    pixel_values = np.array(pixels.split(), dtype=np.float32)\n",
    "    \n",
    "    # Bagi setiap nilai piksel dengan 255 untuk menormalisasi ke [0,1]\n",
    "    normalized_pixel_values = pixel_values / 255.0\n",
    "    \n",
    "    # Ubah kembali array menjadi string agar sesuai dengan format dataframe\n",
    "    return ' '.join(map(str, normalized_pixel_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proceeding the normalize to all row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57418/57418 [08:37<00:00, 110.95it/s] \n"
     ]
    }
   ],
   "source": [
    "# Terapkan normalisasi dengan progress bar\n",
    "tqdm.pandas()  # Untuk menambahkan kemampuan progress bar pada pandas\n",
    "\n",
    "# Normalisasi pada kolom 'resized_pixels' dengan progress bar\n",
    "combined_df_train['resized_pixels'] = combined_df_train['resized_pixels'].progress_apply(normalize_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3589/3589 [01:57<00:00, 30.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Terapkan normalisasi dengan progress bar\n",
    "tqdm.pandas()  # Untuk menambahkan kemampuan progress bar pada pandas\n",
    "\n",
    "# Normalisasi pada kolom 'resized_pixels' dengan progress bar\n",
    "# Menggunakan .loc[] untuk mengubah kolom secara aman\n",
    "df_public_test.loc[:, 'resized_pixels'] = df_public_test['resized_pixels'].progress_apply(normalize_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize datatable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.27058825, 0.2784314, 0.3019608, 0.32941177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.5921569, 0.5921569, 0.5921569, 0.58431375,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.9019608, 0.9098039, 0.8901961, 0.8039216, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.09019608, 0.09803922, 0.10980392, 0.133333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.023529412, 0.011764706, 0.003921569, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     usage                                     resized_pixels\n",
       "0        0  Training  [[0.27058825, 0.2784314, 0.3019608, 0.32941177...\n",
       "1        0  Training  [[0.5921569, 0.5921569, 0.5921569, 0.58431375,...\n",
       "2        2  Training  [[0.9019608, 0.9098039, 0.8901961, 0.8039216, ...\n",
       "3        4  Training  [[0.09019608, 0.09803922, 0.10980392, 0.133333...\n",
       "4        6  Training  [[0.023529412, 0.011764706, 0.003921569, 0.0, ..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilan hasil original + augmentasi dataframe setelah normalisasi\n",
    "combined_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>0</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.99607843 0.99607843 0.99607843 0.99607843 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>1</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.6039216 0.6313726 0.68235296 0.7411765 0.768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>4</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.23529412 0.3137255 0.43137255 0.45490196 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>6</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.83137256 0.8 0.75686276 0.80784315 0.9215686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28713</th>\n",
       "      <td>3</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.3372549 0.33333334 0.32156864 0.30980393 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion       usage                                     resized_pixels\n",
       "28709       0  PublicTest  0.99607843 0.99607843 0.99607843 0.99607843 0....\n",
       "28710       1  PublicTest  0.6039216 0.6313726 0.68235296 0.7411765 0.768...\n",
       "28711       4  PublicTest  0.23529412 0.3137255 0.43137255 0.45490196 0.3...\n",
       "28712       6  PublicTest  0.83137256 0.8 0.75686276 0.80784315 0.9215686...\n",
       "28713       3  PublicTest  0.3372549 0.33333334 0.32156864 0.30980393 0.3..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilan hasil df_public_test dataframe setelah normalisasi\n",
    "df_public_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom emotion: Jika ini adalah label kelas, awalnya tipe object maka bisa mengubahnya menjadi tipe data numerik menggunakan LabelEncoder dari scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "combined_df_train['emotion'] = le.fit_transform(combined_df_train['emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom resized_pixels: Jika kolom ini berisi string yang merepresentasikan array alias saat ini tipe object, maka perlu mengubahnya menjadi array numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi string piksel menjadi array NumPy data train\n",
    "combined_df_train['resized_pixels'] = combined_df_train['resized_pixels'].apply(\n",
    "    lambda x: np.fromstring(x, sep=' ').astype(np.float32).reshape(100, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi string piksel menjadi array NumPy data test\n",
    "df_public_test.loc[:, 'resized_pixels'] = df_public_test['resized_pixels'].apply(\n",
    "    lambda x: np.fromstring(x, sep=' ').astype(np.float32).reshape(100, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Pastikan semua entri memiliki ukuran 100x100\n",
    "print(combined_df_train['resized_pixels'].apply(lambda x: x.shape == (100, 100)).all())\n",
    "print(df_public_test['resized_pixels'].apply(lambda x: x.shape == (100, 100)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.27058825, 0.2784314, 0.3019608, 0.32941177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.5921569, 0.5921569, 0.5921569, 0.58431375,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.9019608, 0.9098039, 0.8901961, 0.8039216, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.09019608, 0.09803922, 0.10980392, 0.133333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.023529412, 0.011764706, 0.003921569, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     usage                                     resized_pixels\n",
       "0        0  Training  [[0.27058825, 0.2784314, 0.3019608, 0.32941177...\n",
       "1        0  Training  [[0.5921569, 0.5921569, 0.5921569, 0.58431375,...\n",
       "2        2  Training  [[0.9019608, 0.9098039, 0.8901961, 0.8039216, ...\n",
       "3        4  Training  [[0.09019608, 0.09803922, 0.10980392, 0.133333...\n",
       "4        6  Training  [[0.023529412, 0.011764706, 0.003921569, 0.0, ..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan informasi dataframe setelah normalisasi\n",
    "combined_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>0</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.99607843, 0.99607843, 0.99607843, 0.996078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>1</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.6039216, 0.6313726, 0.68235296, 0.7411765,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>4</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.23529412, 0.3137255, 0.43137255, 0.4549019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>6</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.83137256, 0.8, 0.75686276, 0.80784315, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28713</th>\n",
       "      <td>3</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.3372549, 0.33333334, 0.32156864, 0.3098039...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion       usage                                     resized_pixels\n",
       "28709       0  PublicTest  [[0.99607843, 0.99607843, 0.99607843, 0.996078...\n",
       "28710       1  PublicTest  [[0.6039216, 0.6313726, 0.68235296, 0.7411765,...\n",
       "28711       4  PublicTest  [[0.23529412, 0.3137255, 0.43137255, 0.4549019...\n",
       "28712       6  PublicTest  [[0.83137256, 0.8, 0.75686276, 0.80784315, 0.9...\n",
       "28713       3  PublicTest  [[0.3372549, 0.33333334, 0.32156864, 0.3098039..."
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan informasi dataframe setelah normalisasi\n",
    "df_public_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixup Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define function Mixup image and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_images_labels(images, labels, alpha=0.2):\n",
    "    \"\"\"Menerapkan Mixup Augmentation pada dua gambar dan label.\n",
    "    \n",
    "    Args:\n",
    "        images (tensor): Tensor gambar-gambar dengan shape (batch_size, channels, height, width).\n",
    "        labels (tensor): Tensor one-hot encoded label dengan shape (batch_size, num_classes).\n",
    "        alpha (float): Parameter distribusi Beta untuk campuran.\n",
    "\n",
    "    Returns:\n",
    "        mixed_images: Gambar campuran.\n",
    "        mixed_labels: Label campuran.\n",
    "    \"\"\"\n",
    "    # Ambil nilai lambda dari distribusi Beta\n",
    "    lambda_val = np.random.beta(alpha, alpha)\n",
    "    \n",
    "    # Pilih dua indeks acak\n",
    "    index = torch.randperm(images.size(0))\n",
    "    \n",
    "    # Gabungkan dua gambar\n",
    "    mixed_images = lambda_val * images + (1 - lambda_val) * images[index, :]\n",
    "    \n",
    "    # Gabungkan label\n",
    "    mixed_labels = lambda_val * labels + (1 - lambda_val) * labels[index, :]\n",
    "    \n",
    "    return mixed_images, mixed_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define function for data preparation before mixup: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan gambar dalam format tensor dan normalisasi ke [0, 1]\n",
    "def prepare_images_labels(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        # Ambil pixel dan konversi ke array numpy\n",
    "        pixels = np.array(df['resized_pixels'][i].split(), dtype=np.float32).reshape(100, 100) / 255.0\n",
    "        \n",
    "        # Tambahkan channel dimension untuk tensor (1 channel karena grayscale)\n",
    "        images.append(pixels[np.newaxis, :, :])\n",
    "        \n",
    "        # Ambil label (ekspresi) dan ubah menjadi one-hot encoding\n",
    "        label = df['emotion'][i]\n",
    "        one_hot_label = np.zeros(8)  # Misal 8 kelas ekspresi\n",
    "        one_hot_label[label] = 1\n",
    "        labels.append(one_hot_label)\n",
    "\n",
    "    # Ubah list ke tensor\n",
    "    images = torch.tensor(np.array(images), dtype=torch.float32)\n",
    "    labels = torch.tensor(np.array(labels), dtype=torch.float32)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiapkan gambar dan label dari combined_df\n",
    "images, labels = prepare_images_labels(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processing Mixup Augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size untuk Mixup Augmentation\n",
    "batch_size = 64  # Batch size 64\n",
    "\n",
    "# Acak gambar dan label untuk setiap batch\n",
    "for i in tqdm(range(0, len(images), batch_size)):\n",
    "    batch_images = images[i:i+batch_size]\n",
    "    batch_labels = labels[i:i+batch_size]\n",
    "    \n",
    "    # Terapkan Mixup Augmentation\n",
    "    mixed_images, mixed_labels = mixup_images_labels(batch_images, batch_labels, alpha=0.2)\n",
    "\n",
    "# (Selanjutnya, mixed_images dan mixed_labels dapat digunakan untuk training model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the result of mixup augmented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_image = mixed_images[0, 0]  # Ambil gambar pertama dari saluran pertama\n",
    "\n",
    "# Ubah tensor ke numpy array\n",
    "image = mixed_image.detach().numpy()  # Mengubah tensor menjadi numpy array\n",
    "\n",
    "# Denormalisasi jika perlu, misal dari rentang [-1, 1] ke [0, 255]\n",
    "image = (image * 0.5 + 0.5) * 255  # Skala ulang ke [0, 255]\n",
    "\n",
    "# Pastikan untuk mengubah tipe data menjadi uint8\n",
    "image = (image * 255).astype(np.uint8)\n",
    "\n",
    "# Tampilkan gambar\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Hilangkan sumbu\n",
    "plt.title(\"Mixed Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konversi DataFrame ke Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.dataframe['resized_pixels'].iloc[idx], dtype=torch.float32).view(1, 100, 100)  # Jika gambar 100x100\n",
    "        label = torch.tensor(self.dataframe['emotion'].iloc[idx], dtype=torch.long)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi dataset\n",
    "train_dataset = EmotionDataset(combined_df_train)\n",
    "test_dataset = EmotionDataset(df_public_test)\n",
    "\n",
    "# Inisialisasi DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBP circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mendapatkan intensitas piksel tetangga menggunakan interpolasi bilinear\n",
    "def get_pixel_value(img, center, x, y):\n",
    "    # Jika tetangga berada di dalam batas gambar\n",
    "    if x >= 0 and x < img.shape[0] and y >= 0 and y < img.shape[1]:\n",
    "        return img[int(x)][int(y)]\n",
    "    else:\n",
    "        return center\n",
    "\n",
    "# Fungsi untuk menghitung Circular LBP pada piksel (x, y)\n",
    "def lbp_calculated_pixel(img, x, y, radius, neighbors):\n",
    "    center = img[x][y]\n",
    "    values = []\n",
    "    \n",
    "    # Looping untuk mengambil nilai tetangga dalam pola melingkar\n",
    "    for n in range(neighbors):\n",
    "        theta = 2 * math.pi * n / neighbors  # Sudut\n",
    "        x_n = x + radius * math.sin(theta)   # Koordinat tetangga dalam pola melingkar\n",
    "        y_n = y + radius * math.cos(theta)\n",
    "        neighbor_value = get_pixel_value(img, center, x_n, y_n)\n",
    "        values.append(1 if neighbor_value >= center else 0)\n",
    "    \n",
    "    # Menghitung nilai biner LBP\n",
    "    lbp_value = 0\n",
    "    for i in range(len(values)):\n",
    "        lbp_value += values[i] * (1 << i)  # 1 << i adalah 2^i\n",
    "    \n",
    "    return lbp_value\n",
    "\n",
    "# Fungsi untuk menghitung Circular LBP untuk seluruh citra\n",
    "def calculate_lbp_image(img, radius=1, neighbors=8):\n",
    "    height, width = img.shape\n",
    "    lbp_image = np.zeros((height, width), dtype=np.uint32)  # Mengubah tipe data ke uint32 untuk mendukung nilai besar\n",
    "    \n",
    "    for i in range(radius, height - radius):\n",
    "        for j in range(radius, width - radius):\n",
    "            lbp_image[i, j] = lbp_calculated_pixel(img, i, j, radius, neighbors)\n",
    "    \n",
    "    # Normalisasi jika diperlukan (mengembalikan nilai dalam rentang 0-255)\n",
    "    lbp_image_normalized = np.uint8(lbp_image / lbp_image.max() * 255)\n",
    "    \n",
    "    return lbp_image_normalized\n",
    "\n",
    "# Fungsi untuk menampilkan hasil\n",
    "def show_output(original_img, lbp_img):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Gambar asli (grayscale)\n",
    "    axs[0].imshow(original_img, cmap='gray')\n",
    "    axs[0].set_title('Original Grayscale Image')\n",
    "    \n",
    "    # Hasil LBP\n",
    "    axs[1].imshow(lbp_img, cmap='gray')\n",
    "    axs[1].set_title('Circular LBP Image')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Fungsi untuk ekstraksi fitur LBP dari batch gambar\n",
    "def lbp_feature_extraction_batch(images, radius=3, neighbors=24):\n",
    "    lbp_features = []\n",
    "    for img in images:\n",
    "        lbp_img = calculate_lbp_image(img.squeeze().cpu().numpy(), radius, neighbors)  # Ekstraksi LBP dari gambar\n",
    "        lbp_hist, _ = np.histogram(lbp_img.ravel(), bins=np.arange(0, neighbors + 3), range=(0, neighbors + 2))\n",
    "        lbp_hist = lbp_hist.astype(\"float\")\n",
    "        lbp_hist /= lbp_hist.sum()  # Normalisasi histogram\n",
    "        lbp_features.append(lbp_hist)\n",
    "\n",
    "    return np.array(lbp_features)\n",
    "    \n",
    "neighbors=24 # samakan dengan tabel dari referensi circular lbp ini yang optimal\n",
    "\n",
    "# Definisikan ukuran fitur LBP\n",
    "lbp_feature_size = neighbors + 2  # Misalnya 26 untuk 24 neighbors  \n",
    "\n",
    "# Main function\n",
    "# def lbp_feature_extraction(image):\n",
    "#     # Membaca citra\n",
    "#     # image_file = '../src/lenna.jpg'\n",
    "#     image_file = image\n",
    "#     img_bgr = cv2.imread(image_file)\n",
    "#     img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Hitung LBP dengan radius 3 dan 24 tetangga\n",
    "#     lbp_img = calculate_lbp_image(img_gray, radius=3, neighbors=24)\n",
    "    \n",
    "#     # Tampilkan hasilnya\n",
    "#     show_output(img_gray, lbp_img)\n",
    "\n",
    "#     return lbp_img\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     lbp_img = lbp_feature_extraction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengonversi Output LBP menjadi Vektor dan Menghubungkan ke FC Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        # MLP\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // ratio, kernel_size=1, bias=False)\n",
    "        self.fc2 = nn.Conv2d(in_channels // ratio, in_channels, kernel_size=1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# Spatial Attention Module\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# CBAM Module (Channel + Spatial Attention)\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, ratio)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.channel_attention(x)\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ResNet18_CBAM, self).__init__()\n",
    "        \n",
    "        self.dropout_percentage = 0.5\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # BLOCK-1 (starting block) input=(224x224) output=(56x56)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        \n",
    "        # CBAM after block1\n",
    "        self.cbam1 = CBAM(64)\n",
    "\n",
    "        # BLOCK-2 (1) input=(56x56) output = (56x56)\n",
    "        self.conv2_1_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_1_1 = nn.BatchNorm2d(64)\n",
    "        self.conv2_1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_1_2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-2 (2)\n",
    "        self.conv2_2_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_2_1 = nn.BatchNorm2d(64)\n",
    "        self.conv2_2_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_2_2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # CBAM after block2\n",
    "        self.cbam2 = CBAM(64)\n",
    "        \n",
    "        # BLOCK-3 (1) input=(56x56) output = (28x28)\n",
    "        self.conv3_1_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm3_1_1 = nn.BatchNorm2d(128)\n",
    "        self.conv3_1_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_1_2 = nn.BatchNorm2d(128)\n",
    "        self.concat_adjust_3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout3_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-3 (2)\n",
    "        self.conv3_2_1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_2_1 = nn.BatchNorm2d(128)\n",
    "        self.conv3_2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_2_2 = nn.BatchNorm2d(128)\n",
    "        self.dropout3_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # CBAM after block3\n",
    "        self.cbam3 = CBAM(128)\n",
    "\n",
    "        # BLOCK-4 (1) input=(28x28) output = (14x14)\n",
    "        self.conv4_1_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm4_1_1 = nn.BatchNorm2d(256)\n",
    "        self.conv4_1_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_1_2 = nn.BatchNorm2d(256)\n",
    "        self.concat_adjust_4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout4_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-4 (2)\n",
    "        self.conv4_2_1 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_2_1 = nn.BatchNorm2d(256)\n",
    "        self.conv4_2_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_2_2 = nn.BatchNorm2d(256)\n",
    "        self.dropout4_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # CBAM after block4\n",
    "        self.cbam4 = CBAM(256)\n",
    "\n",
    "        # BLOCK-5 (1) input=(14x14) output = (7x7)\n",
    "        self.conv5_1_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm5_1_1 = nn.BatchNorm2d(512)\n",
    "        self.conv5_1_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_1_2 = nn.BatchNorm2d(512)\n",
    "        self.concat_adjust_5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout5_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-5 (2)\n",
    "        self.conv5_2_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv5_2_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_2_2 = nn.BatchNorm2d(512)\n",
    "        self.dropout5_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # CBAM after block5\n",
    "        self.cbam5 = CBAM(512)\n",
    "        \n",
    "        # Final Block input=(7x7) \n",
    "        # self.avgpool = nn.AvgPool2d(kernel_size=(7, 7), stride=(7, 7))  # Mengubah output menjadi (512, 1, 1)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(4, 4), stride=(4, 4))  # Output akan menjadi (512, 1, 1)\n",
    "        self.fc = nn.Linear(in_features=1 * 1 * 512, out_features=1000)  # 512 dari avgpool\n",
    "        self.out = nn.Linear(in_features=1000, out_features=n_classes)  # n_classes sesuai dengan jumlah kelas\n",
    "        # END\n",
    "\n",
    "    def forward(self, x):\n",
    "        # block 1 --> Starting block\n",
    "        x = self.relu(self.batchnorm1(self.conv1(x)))\n",
    "        op1 = self.maxpool1(x)\n",
    "        op1 = self.cbam1(op1)\n",
    "        # print(f\"Output after Block 1: {op1.shape}\")  # Cek ukuran output\n",
    "        \n",
    "        # block2 - 1\n",
    "        x = self.relu(self.batchnorm2_1_1(self.conv2_1_1(op1)))    # conv2_1 \n",
    "        x = self.batchnorm2_1_2(self.conv2_1_2(x))                 # conv2_1\n",
    "        x = self.dropout2_1(x)\n",
    "        # block2 - Adjust - No adjust in this layer as dimensions are already same\n",
    "        # block2 - Concatenate 1\n",
    "        op2_1 = self.relu(x + op1)\n",
    "        # block2 - 2\n",
    "        x = self.relu(self.batchnorm2_2_1(self.conv2_2_1(op2_1)))  # conv2_2 \n",
    "        x = self.batchnorm2_2_2(self.conv2_2_2(x))                 # conv2_2\n",
    "        x = self.dropout2_2(x)\n",
    "        # op - block2\n",
    "        op2 = self.relu(x + op2_1)\n",
    "        op2 = self.cbam2(op2)\n",
    "        # print(f\"Output after Block 2: {op2.shape}\")  # Cek ukuran output\n",
    "        \n",
    "        # block3 - 1[Convolution block]\n",
    "        x = self.relu(self.batchnorm3_1_1(self.conv3_1_1(op2)))    # conv3_1\n",
    "        x = self.batchnorm3_1_2(self.conv3_1_2(x))                 # conv3_1\n",
    "        x = self.dropout3_1(x)\n",
    "        # block3 - Adjust\n",
    "        op2 = self.concat_adjust_3(op2) # SKIP CONNECTION\n",
    "        # block3 - Concatenate 1\n",
    "        op3_1 = self.relu(x + op2)\n",
    "        # block3 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm3_2_1(self.conv3_2_1(op3_1)))  # conv3_2\n",
    "        x = self.batchnorm3_2_2(self.conv3_2_2(x))                 # conv3_2 \n",
    "        x = self.dropout3_2(x)\n",
    "        # op - block3\n",
    "        op3 = self.relu(x + op3_1)\n",
    "        op3 = self.cbam3(op3)\n",
    "        # print(f\"Output after Block 3: {op3.shape}\")  # Cek ukuran output\n",
    "\n",
    "        # block4 - 1[Convolition block]\n",
    "        x = self.relu(self.batchnorm4_1_1(self.conv4_1_1(op3)))    # conv4_1\n",
    "        x = self.batchnorm4_1_2(self.conv4_1_2(x))                 # conv4_1\n",
    "        x = self.dropout4_1(x)\n",
    "        # block4 - Adjust\n",
    "        op3 = self.concat_adjust_4(op3) # SKIP CONNECTION\n",
    "        # block4 - Concatenate 1\n",
    "        op4_1 = self.relu(x + op3)\n",
    "        # block4 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm4_2_1(self.conv4_2_1(op4_1)))  # conv4_2\n",
    "        x = self.batchnorm4_2_2(self.conv4_2_2(x))                 # conv4_2\n",
    "        x = self.dropout4_2(x)\n",
    "        # op - block4\n",
    "        op4 = self.relu(x + op4_1)\n",
    "        op4 = self.cbam4(op4)\n",
    "        # print(f\"Output after Block 4: {op4.shape}\")  # Cek ukuran output\n",
    "\n",
    "        # block5 - 1[Convolution Block]\n",
    "        x = self.relu(self.batchnorm5_1_1(self.conv5_1_1(op4)))    # conv5_1\n",
    "        x = self.batchnorm5_1_2(self.conv5_1_2(x))                 # conv5_1\n",
    "        x = self.dropout5_1(x)\n",
    "        # block5 - Adjust\n",
    "        op4 = self.concat_adjust_5(op4) # SKIP CONNECTION\n",
    "        # block5 - Concatenate 1\n",
    "        op5_1 = self.relu(x + op4)\n",
    "        # block5 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm5_2_1(self.conv5_2_1(op5_1)))  # conv5_2\n",
    "        x = self.batchnorm5_2_2(self.conv5_2_2(x))                 # conv5_2\n",
    "        x = self.dropout5_2(x)\n",
    "        # op - block5\n",
    "        op5 = self.relu(x + op5_1)\n",
    "        op5 = self.cbam5(op5)\n",
    "        # print(f\"Output after Block 5: {op5.shape}\")  # Cek ukuran output\n",
    "        \n",
    "        # final operations\n",
    "        x = self.avgpool(op5)\n",
    "        # print(f\"Shape after avgpool: {x.shape}\")\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(f\"Shape after flatten: {x.shape}\")\n",
    "        xfeatures = self.fc(x)\n",
    "        # print(f\"Output after fc: {x.shape}\")  # Cek ukuran output\n",
    "        # x = self.out(x) # Jangan panggil self.out\n",
    "        # print(f\"Output self.out: {x.shape}\")  # Cek ukuran output\n",
    "        return xfeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, n_classes, lbp_feature_size):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.resnet = ResNet18_CBAM(n_classes)\n",
    "        self.fc_lbp = nn.Linear(lbp_feature_size, 128)  # Ubah lbp_feature_size sesuai ukuran LBP\n",
    "        self.fc_combined = nn.Linear(128 + 1000, n_classes)  # Gabungkan output LBP dan ResNet\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ekstraksi fitur LBP\n",
    "        lbp_features = lbp_feature_extraction_batch(x)  # Ekstrak fitur LBP\n",
    "        lbp_features = torch.from_numpy(lbp_features).float().to(x.device)  # Konversi ke tensor dan pindahkan ke device\n",
    "        lbp_features = lbp_features.view(lbp_features.size(0), -1)  # Flatten jika perlu\n",
    "        # print(f\"LBP feature size: {lbp_features.shape}\")\n",
    "        \n",
    "        # Proses fitur LBP\n",
    "        lbp_features = self.fc_lbp(lbp_features)\n",
    "        # print(f\"Processed LBP feature size: {lbp_features.shape}\")\n",
    "        \n",
    "        # Proses melalui ResNet (output fitur sebelum klasifikasi akhir)\n",
    "        resnet_output = self.resnet(x)  # Output [32,1000]\n",
    "        # print(f\"ResNet output size: {resnet_output.shape}\")\n",
    "        \n",
    "        # Gabungkan output LBP dan ResNet\n",
    "        combined = torch.cat((lbp_features, resnet_output), dim=1)  # [32,1128]\n",
    "        # print(f\"Combined feature size: {combined.shape}\")\n",
    "        \n",
    "        # Proses melalui fully connected layer\n",
    "        output = self.fc_combined(combined)  # [32,7]\n",
    "        # print(f\"Output after fc_combined: {output.shape}\")\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model dengan Batch Processing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memastikan tidak ada diluar rentang 0-6 pada label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor(combined_df_train['emotion'].values)\n",
    "print(labels.unique())  # Pastikan label tidak ada yang out-of-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')\n",
    "# model = CombinedModel(n_classes=7, lbp_feature_size=lbp_feature_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 2/225 [02:36<4:51:16, 78.37s/it, Loss=1.87]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[109], line 10\u001b[0m, in \u001b[0;36mCombinedModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Ekstraksi fitur LBP\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     lbp_features \u001b[38;5;241m=\u001b[39m \u001b[43mlbp_feature_extraction_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ekstrak fitur LBP\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     lbp_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(lbp_features)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# Konversi ke tensor dan pindahkan ke device\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     lbp_features \u001b[38;5;241m=\u001b[39m lbp_features\u001b[38;5;241m.\u001b[39mview(lbp_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten jika perlu\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[106], line 61\u001b[0m, in \u001b[0;36mlbp_feature_extraction_batch\u001b[1;34m(images, radius, neighbors)\u001b[0m\n\u001b[0;32m     59\u001b[0m lbp_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m---> 61\u001b[0m     lbp_img \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_lbp_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ekstraksi LBP dari gambar\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     lbp_hist, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(lbp_img\u001b[38;5;241m.\u001b[39mravel(), bins\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, neighbors \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m), \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, neighbors \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     63\u001b[0m     lbp_hist \u001b[38;5;241m=\u001b[39m lbp_hist\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[106], line 36\u001b[0m, in \u001b[0;36mcalculate_lbp_image\u001b[1;34m(img, radius, neighbors)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(radius, height \u001b[38;5;241m-\u001b[39m radius):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(radius, width \u001b[38;5;241m-\u001b[39m radius):\n\u001b[1;32m---> 36\u001b[0m         lbp_image[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mlbp_calculated_pixel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Normalisasi jika diperlukan (mengembalikan nilai dalam rentang 0-255)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m lbp_image_normalized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(lbp_image \u001b[38;5;241m/\u001b[39m lbp_image\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\n",
      "Cell \u001b[1;32mIn[106], line 19\u001b[0m, in \u001b[0;36mlbp_calculated_pixel\u001b[1;34m(img, x, y, radius, neighbors)\u001b[0m\n\u001b[0;32m     17\u001b[0m     x_n \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m radius \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msin(theta)   \u001b[38;5;66;03m# Koordinat tetangga dalam pola melingkar\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     y_n \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m radius \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(theta)\n\u001b[1;32m---> 19\u001b[0m     neighbor_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_pixel_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m neighbor_value \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m center \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Menghitung nilai biner LBP\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[106], line 5\u001b[0m, in \u001b[0;36mget_pixel_value\u001b[1;34m(img, center, x, y)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pixel_value\u001b[39m(img, center, x, y):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Jika tetangga berada di dalam batas gambar\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x \u001b[38;5;241m<\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;241m<\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m----> 5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img[\u001b[38;5;28mint\u001b[39m(x)][\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m center\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Inisialisasi model dan optimasi\n",
    "model = CombinedModel(n_classes=7, lbp_feature_size=lbp_feature_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.1, weight_decay=0.0001)\n",
    "\n",
    "# Variabel untuk menyimpan akurasi terbaik\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Training loop dengan validasi\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Loss': loss.item()})\n",
    "    \n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "    # Validasi\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Simpan model jika akurasi lebih baik dari sebelumnya\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        # Simpan model dan optimizer state\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'accuracy': accuracy,\n",
    "        }\n",
    "        torch.save(checkpoint, f'model_checkpoint_epoch_{epoch + 1}.pt')\n",
    "        print(f\"Model disimpan dengan akurasi terbaik: {accuracy:.2f}% pada epoch {epoch + 1}\")\n",
    "\n",
    "print(\"Training dan validasi selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
