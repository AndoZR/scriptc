{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analys The Problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously on papper \"Facial Expression Recognition Methods in the Wild Based on Fusion Feature of Attention Mechanism and LBP (MDPI Sensors 2023 Q2)\" authors used a model called ResNet-50 combined CBAM and LBP.\n",
    "\n",
    "The accuracy took:\n",
    "- 99.66% on CK+\n",
    "- 74.23% on FER-2013\n",
    "- 89.50 on FER-PLUS \n",
    "- 88.20 on RAF-DB\n",
    "\n",
    "**The problem: What if I change the variant of LBP in this method, does it increase the accuracy spesifically for FER-2013 dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **About Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The paper used 4 dataset include CK+(59 images), FER-2013 (35,887 images), FER-PLUS(31.412 images), RAF-DB (29,672 images)\n",
    "- CK+ is a controlled dataset and the 3 others datasets are uncontrolled datasets\n",
    "- Controlled dataset has good lightning and pose but uncontrolled datasets got a random of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ResNet-18 + CBAM**\n",
    "\n",
    "    1. Architecture of ResNet-18:\n",
    "    \n",
    "        <img src=\"../src/Structure-of-a-ResNet-18-architecture.png\" alt=\"Windowing of Feature in Faces\" width=\"350\" height=\"250\">\n",
    "\n",
    "    2. CBAM Architecture:\n",
    "\n",
    "        <img src=\"../src/cbam.png\" alt=\"Windowing of Feature in Faces\" width=\"600\" height=\"100\">\n",
    "\n",
    "    3. Authors combine the CBAM module into each block of the ResNet-18 architecture,\n",
    "    \n",
    "        Before and After implement the CBAM module:\n",
    "\n",
    "        <img src=\"../src/oriblock.png\" alt=\"Windowing of Feature in Faces\" width=\"150\" height=\"200\">\n",
    "        <img src=\"../src/blocknCbam.png\" alt=\"Windowing of Feature in Faces\" width=\"150\" height=\"200\">\n",
    "\n",
    "- **Local Binary Patterns (LBP)**\n",
    "\n",
    "    LBP is one of the most generally used texture pattern descriptors for examining local grain features and is regarded as one of the best methods for texture processing, which is widely employed in image processing.\n",
    "\n",
    "- **RCL-Net Model**\n",
    "\n",
    "    After combining all the method such as LBP and ResNet-CBAM, this architecture called by **RCL-Net Model**,\n",
    "\n",
    "    <img src=\"../src/rcl-net.png\" alt=\"Windowing of Feature in Faces\" width=\"700\" height=\"200\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In planning, switching LBP method in previous architecture with the newest or other variant LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for augmen:\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# for mixup augmen:\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# mixup from train.py file\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# LBP\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Bersihkan cache CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA LOADING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca file CSV\n",
    "# file_path_train = 'D:/Ando File 4 Kuliah/A SKRIPSI/RISETku/KERJA/DATA/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv'  # Ganti dengan lokasi file kamu\n",
    "# df_train = pd.read_csv(file_path_train)\n",
    "\n",
    "# file_path_test = 'D:/Ando File 4 Kuliah/A SKRIPSI/RISETku/KERJA/DATA/challenges-in-representation-learning-facial-expression-recognition-challenge/test.csv'  # Ganti dengan lokasi file kamu\n",
    "# df_test = pd.read_csv(file_path_test)\n",
    "\n",
    "file_path = 'D:/Ando File 4 Kuliah/A SKRIPSI/RISETku/KERJA/DATA/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv'  # Ganti dengan lokasi file kamu\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the data on datatables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     Usage                                             pixels\n",
       "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREPROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resized Image 100 x 100:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define function resized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengubah string pixel menjadi gambar\n",
    "def convert_to_image(pixels, size=(48, 48), new_size=(100, 100)):\n",
    "    # Ubah string pixel menjadi array\n",
    "    pixel_values = np.array(pixels.split(), dtype=np.uint8)\n",
    "    \n",
    "    # Ubah array 1D menjadi array 2D\n",
    "    image = pixel_values.reshape(size)\n",
    "    \n",
    "    # Buat gambar dari array 2D\n",
    "    img = Image.fromarray(image)\n",
    "    \n",
    "    # Ubah ukuran gambar menggunakan LANCZOS untuk kualitas terbaik\n",
    "    resized_img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processing the resize to all images and saved to new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 35887/35887 [02:59<00:00, 200.09it/s]\n"
     ]
    }
   ],
   "source": [
    "df_resized = pd.DataFrame(columns=['emotion', 'usage', 'resized_pixels']) # DataFrame baru untuk menyimpan gambar yang sudah diproses\n",
    "\n",
    "# Proses setiap baris di DataFrame asli dengan progress bar\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\"):\n",
    "    pixels = row[' pixels']\n",
    "    \n",
    "    # Konversi pixel menjadi gambar dan resize\n",
    "    resized_image = convert_to_image(pixels)\n",
    "    \n",
    "    # Ubah gambar yang diresize menjadi array 1D untuk disimpan dalam DataFrame\n",
    "    resized_image_array = np.array(resized_image).flatten()\n",
    "    \n",
    "    # Buat DataFrame baru untuk baris ini\n",
    "    new_row = pd.DataFrame({\n",
    "        'emotion': [row['emotion']],\n",
    "        'usage': [row[' Usage']],\n",
    "        'resized_pixels': [' '.join(resized_image_array.astype(str))]\n",
    "    })\n",
    "    \n",
    "    # Gabungkan baris baru dengan DataFrame yang sudah ada\n",
    "    df_resized = pd.concat([df_resized, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking info of dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   emotion         35887 non-null  object\n",
      " 1   usage           35887 non-null  object\n",
      " 2   resized_pixels  35887 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_resized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35887</td>\n",
       "      <td>35887</td>\n",
       "      <td>35887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>34034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3</td>\n",
       "      <td>Training</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8989</td>\n",
       "      <td>28709</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        emotion     usage                                     resized_pixels\n",
       "count     35887     35887                                              35887\n",
       "unique        7         3                                              34034\n",
       "top           3  Training  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "freq       8989     28709                                                 12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>69 71 77 84 86 84 80 72 64 59 57 57 57 58 61 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 151 151 149 147 148 152 155 153 148 144 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>230 232 227 205 173 154 153 166 178 175 154 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>23 25 28 34 37 36 32 29 31 32 28 23 20 19 18 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>6 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion     usage                                     resized_pixels\n",
       "0       0  Training  69 71 77 84 86 84 80 72 64 59 57 57 57 58 61 6...\n",
       "1       0  Training  151 151 151 149 147 148 152 155 153 148 144 13...\n",
       "2       2  Training  230 232 227 205 173 154 153 166 178 175 154 13...\n",
       "3       4  Training  23 25 28 34 37 36 32 29 31 32 28 23 20 19 18 2...\n",
       "4       6  Training  6 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking column's names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emotion', 'usage', 'resized_pixels'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resized.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking unique value in \"Usage\" columnns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Training', 'PublicTest', 'PrivateTest'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resized['usage'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating between trai, public, and private test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data yang Usage-nya \"Training\"\n",
    "df_train = df_resized[df_resized['usage'] == 'Training']\n",
    "df_public_test = df_resized[df_resized['usage'] == 'PublicTest']\n",
    "df_private_test = df_resized[df_resized['usage'] == 'PrivateTest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking total of row and column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 3)\n",
      "(3589, 3)\n",
      "(3589, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_public_test.shape)\n",
    "print(df_private_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before Resized 48x48:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ambil data pixels dari baris yang diinginkan\n",
    "row_index = 0  # Ganti dengan indeks baris yang diinginkan\n",
    "pixels = df[' pixels'][row_index]\n",
    "\n",
    "# Ubah string pixel menjadi array 1D\n",
    "pixel_values = np.array(pixels.split(), dtype=np.uint8)\n",
    "\n",
    "# Ubah array 1D menjadi array 2D\n",
    "image = pixel_values.reshape(48, 48)\n",
    "\n",
    "# Tampilkan gambar\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Emotion: {df['emotion'][row_index]}\")\n",
    "plt.axis('off')  # Hilangkan sumbu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After resized 100x100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ambil data pixels dari baris yang diinginkan\n",
    "row_index = 0  # indeks baris yang diinginkan\n",
    "pixels = df_resized['resized_pixels'][row_index]\n",
    "\n",
    "# Ubah string pixel menjadi array 1D\n",
    "pixel_values = np.array(pixels.split(), dtype=np.uint8)\n",
    "\n",
    "# Ubah array 1D menjadi array 2D (100x100)\n",
    "image = pixel_values.reshape(100, 100)\n",
    "\n",
    "# Tampilkan gambar\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Emotion: {df_resized['emotion'][row_index]}\")\n",
    "plt.axis('off')  # Hilangkan sumbu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menerapkan minimum data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "0    3995\n",
      "1     436\n",
      "2    4097\n",
      "3    7215\n",
      "4    4830\n",
      "5    3171\n",
      "6    4965\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Menghitung total data per label pada kolom 'emotion'\n",
    "label_counts = df_train.groupby('emotion').size()\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "0    436\n",
      "1    436\n",
      "2    436\n",
      "3    436\n",
      "4    436\n",
      "5    436\n",
      "6    436\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tentukan jumlah data yang diinginkan per label\n",
    "desired_count = 436\n",
    "\n",
    "# List untuk menyimpan DataFrame setiap label setelah disampling\n",
    "balanced_dataframes = []\n",
    "\n",
    "# Loop untuk setiap label di kolom 'emotion'\n",
    "for label, group in df_train.groupby('emotion'):\n",
    "    if len(group) > desired_count:\n",
    "        # Jika jumlah data lebih dari desired_count, lakukan undersampling\n",
    "        sampled_group = group.sample(n=desired_count, random_state=42)\n",
    "    else:\n",
    "        # Jika jumlah data kurang atau sama dengan desired_count, gunakan semua data\n",
    "        sampled_group = group\n",
    "    \n",
    "    # Tambahkan data yang telah disampling ke dalam list\n",
    "    balanced_dataframes.append(sampled_group)\n",
    "\n",
    "# Gabungkan semua data yang telah diundersampling menjadi satu DataFrame\n",
    "balanced_df_train = pd.concat(balanced_dataframes)\n",
    "\n",
    "# Menampilkan total data per label setelah undersampling\n",
    "print(balanced_df_train.groupby('emotion').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indeks setelah melakukan sampling atau filtering\n",
    "balanced_df_train = balanced_df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>136 129 115 100 89 79 67 53 37 26 25 29 33 35 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>25 23 18 17 22 29 34 34 31 26 25 24 22 24 32 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>229 226 222 216 214 212 212 211 213 215 218 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>220 223 225 229 224 189 127 83 76 88 92 90 89 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>71 79 93 108 108 92 64 42 41 52 63 71 76 78 83...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion     usage                                     resized_pixels\n",
       "0       0  Training  136 129 115 100 89 79 67 53 37 26 25 29 33 35 ...\n",
       "1       0  Training  25 23 18 17 22 29 34 34 31 26 25 24 22 24 32 4...\n",
       "2       0  Training  229 226 222 216 214 212 212 211 213 215 218 22...\n",
       "3       0  Training  220 223 225 229 224 189 127 83 76 88 92 90 89 ...\n",
       "4       0  Training  71 79 93 108 108 92 64 42 41 52 63 71 76 78 83..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3052, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmantation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define augmentation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi augmentasi\n",
    "def augment_image(image):\n",
    "    # Pipeline augmentasi menggunakan albumentations\n",
    "    transform = A.Compose([\n",
    "        A.RandomCrop(width=90, height=90),         # Random crop ukuran 80x80 dari gambar asli (100x100)\n",
    "        A.HorizontalFlip(p=0.5),                   # Membalik gambar secara horizontal dengan probabilitas 50%\n",
    "        A.Rotate(limit=20, p=0.5),                 # Memutar gambar dengan sudut hingga 20 derajat\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),  # Jitter warna\n",
    "        A.CoarseDropout(max_holes=4, max_height=5, max_width=5, p=0.5),  # Random masking\n",
    "        A.Resize(100, 100),                        # Resize kembali menjadi ukuran 100x100\n",
    "        # A.Normalize(mean=(0.5,), std=(0.5,)),      # Dibuatr normalize 0,1 agar bentuknya kembali semula kalo ini dihilangkan outputnya pecah, gak jadi ini setelah augmentasi\n",
    "        ToTensorV2()                               # Ubah gambar menjadi tensor PyTorch\n",
    "    ])\n",
    "    \n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processing the augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 3052/3052 [00:12<00:00, 252.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# List untuk menyimpan hasil augmentasi\n",
    "augmented_images = []\n",
    "augmented_emotions = []\n",
    "\n",
    "# Proses augmentasi untuk setiap gambar di dataframe asli\n",
    "for i in tqdm(range(len(balanced_df_train)), desc=\"Augmenting images\"):\n",
    "    # Ambil gambar dari dataframe dan ubah menjadi array 2D\n",
    "    pixels = np.array(balanced_df_train['resized_pixels'][i].split(), dtype=np.uint8).reshape(100, 100)\n",
    "    \n",
    "    # Augmentasi gambar\n",
    "    augmented_image = augment_image(pixels)\n",
    "    \n",
    "    # Ubah tensor augmented_image kembali ke numpy array, lalu ubah jadi string lagi untuk disimpan di dataframe\n",
    "    augmented_image_np = augmented_image.permute(1, 2, 0).numpy().flatten().tolist()  # Ubah ke list 1D\n",
    "    augmented_image_str = ' '.join(map(str, augmented_image_np))  # Ubah list jadi string\n",
    "    \n",
    "    # Simpan gambar yang sudah di-augmentasi dan emosi ke list\n",
    "    augmented_images.append(augmented_image_str)\n",
    "    augmented_emotions.append(balanced_df_train['emotion'][i])\n",
    "\n",
    "# Masukkan hasil augmentasi ke dataframe baru\n",
    "augmented_df_train = pd.DataFrame({\n",
    "    'emotion': augmented_emotions,\n",
    "    'resized_pixels': augmented_images\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30 28 29 29 23 15 10 8 10 11 11 11 10 10 10 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>77 83 88 93 98 102 107 113 116 119 122 126 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>222 225 229 232 234 236 238 240 240 239 234 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>69 78 82 81 76 68 62 62 71 86 102 115 123 127 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>60 59 56 50 43 36 32 33 39 46 49 47 48 47 47 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>6</td>\n",
       "      <td>100 95 98 102 102 101 100 100 101 100 96 96 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>6</td>\n",
       "      <td>1 1 2 3 4 3 3 3 3 4 4 4 4 3 3 7 15 24 33 39 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>6</td>\n",
       "      <td>157 143 106 64 32 22 31 41 41 34 28 24 22 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>6</td>\n",
       "      <td>232 232 231 231 230 230 229 229 229 228 228 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>6</td>\n",
       "      <td>26 5 0 0 0 0 0 0 1 8 21 22 11 2 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3052 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion                                     resized_pixels\n",
       "0           0  30 28 29 29 23 15 10 8 10 11 11 11 10 10 10 10...\n",
       "1           0  77 83 88 93 98 102 107 113 116 119 122 126 129...\n",
       "2           0  222 225 229 232 234 236 238 240 240 239 234 23...\n",
       "3           0  69 78 82 81 76 68 62 62 71 86 102 115 123 127 ...\n",
       "4           0  60 59 56 50 43 36 32 33 39 46 49 47 48 47 47 4...\n",
       "...       ...                                                ...\n",
       "3047        6  100 95 98 102 102 101 100 100 101 100 96 96 10...\n",
       "3048        6  1 1 2 3 4 3 3 3 3 4 4 4 4 3 3 7 15 24 33 39 46...\n",
       "3049        6  157 143 106 64 32 22 31 41 41 34 28 24 22 24 3...\n",
       "3050        6  232 232 231 231 230 230 229 229 229 228 228 22...\n",
       "3051        6  26 5 0 0 0 0 0 0 1 8 21 22 11 2 0 0 0 0 0 0 0 ...\n",
       "\n",
       "[3052 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize image after augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ambil data pixels dari baris yang diinginkan\n",
    "row_index = 0  # Ganti dengan indeks baris yang diinginkan\n",
    "pixels = augmented_df_train['resized_pixels'][row_index]\n",
    "\n",
    "# Ubah string pixel menjadi array 1D (float)\n",
    "pixel_values = np.array(pixels.split(), dtype=np.float32)\n",
    "\n",
    "# Denormalisasi dari rentang [-1, 1] ke [0, 255]\n",
    "# pixel_values = (pixel_values * 0.5 + 0.5) * 255  # Skala ulang ke [0, 255]\n",
    "\n",
    "# Ubah array 1D menjadi array 2D (100x100)\n",
    "image = pixel_values.reshape(100, 100)\n",
    "\n",
    "# Ubah ke tipe data uint8 agar bisa ditampilkan sebagai gambar\n",
    "image = image.astype(np.uint8)\n",
    "\n",
    "# Tampilkan gambar\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Emotion: {augmented_df_train['emotion'][row_index]}\")\n",
    "plt.axis('off')  # Hilangkan sumbu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Append the new augmentation into original dataframe before the augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data setelah augmentasi: 6104\n",
      "  emotion     usage                                     resized_pixels\n",
      "0       0  Training  136 129 115 100 89 79 67 53 37 26 25 29 33 35 ...\n",
      "1       0  Training  25 23 18 17 22 29 34 34 31 26 25 24 22 24 32 4...\n",
      "2       0  Training  229 226 222 216 214 212 212 211 213 215 218 22...\n",
      "3       0  Training  220 223 225 229 224 189 127 83 76 88 92 90 89 ...\n",
      "4       0  Training  71 79 93 108 108 92 64 42 41 52 63 71 76 78 83...\n"
     ]
    }
   ],
   "source": [
    "# Gabungkan dataframe asli dengan dataframe augmented\n",
    "combined_df_train = pd.concat([balanced_df_train, augmented_df_train], ignore_index=True)\n",
    "\n",
    "# Tampilkan informasi jumlah data\n",
    "print(f\"Jumlah data setelah augmentasi: {len(combined_df_train)}\")\n",
    "\n",
    "# Tampilkan contoh baris dari dataframe gabungan\n",
    "print(combined_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define function normalize pixel to [0,1] dividing by 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk normalisasi nilai piksel\n",
    "def normalize_pixels(pixels):\n",
    "    # Ubah string pixel menjadi array float\n",
    "    pixel_values = np.array(pixels.split(), dtype=np.float32)\n",
    "    \n",
    "    # Bagi setiap nilai piksel dengan 255 untuk menormalisasi ke [0,1]\n",
    "    normalized_pixel_values = pixel_values / 255.0\n",
    "    \n",
    "    # Ubah kembali array menjadi string agar sesuai dengan format dataframe\n",
    "    return ' '.join(map(str, normalized_pixel_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proceeding the normalize to all row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6104/6104 [00:33<00:00, 184.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Terapkan normalisasi dengan progress bar\n",
    "tqdm.pandas()  # Untuk menambahkan kemampuan progress bar pada pandas\n",
    "\n",
    "# Normalisasi pada kolom 'resized_pixels' dengan progress bar\n",
    "combined_df_train['resized_pixels'] = combined_df_train['resized_pixels'].progress_apply(normalize_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3589/3589 [00:19<00:00, 179.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Terapkan normalisasi dengan progress bar\n",
    "tqdm.pandas()  # Untuk menambahkan kemampuan progress bar pada pandas\n",
    "\n",
    "# Normalisasi pada kolom 'resized_pixels' dengan progress bar\n",
    "# Menggunakan .loc[] untuk mengubah kolom secara aman\n",
    "df_public_test.loc[:, 'resized_pixels'] = df_public_test['resized_pixels'].progress_apply(normalize_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize datatable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.53333336 0.5058824 0.4509804 0.39215687 0.34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.09803922 0.09019608 0.07058824 0.06666667 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.8980392 0.8862745 0.87058824 0.84705883 0.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.8627451 0.8745098 0.88235295 0.8980392 0.878...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.2784314 0.30980393 0.3647059 0.42352942 0.42...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion     usage                                     resized_pixels\n",
       "0       0  Training  0.53333336 0.5058824 0.4509804 0.39215687 0.34...\n",
       "1       0  Training  0.09803922 0.09019608 0.07058824 0.06666667 0....\n",
       "2       0  Training  0.8980392 0.8862745 0.87058824 0.84705883 0.83...\n",
       "3       0  Training  0.8627451 0.8745098 0.88235295 0.8980392 0.878...\n",
       "4       0  Training  0.2784314 0.30980393 0.3647059 0.42352942 0.42..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilan hasil original + augmentasi dataframe setelah normalisasi\n",
    "combined_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>0</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.99607843 0.99607843 0.99607843 0.99607843 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>1</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.6039216 0.6313726 0.68235296 0.7411765 0.768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>4</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.23529412 0.3137255 0.43137255 0.45490196 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>6</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.83137256 0.8 0.75686276 0.80784315 0.9215686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28713</th>\n",
       "      <td>3</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>0.3372549 0.33333334 0.32156864 0.30980393 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion       usage                                     resized_pixels\n",
       "28709       0  PublicTest  0.99607843 0.99607843 0.99607843 0.99607843 0....\n",
       "28710       1  PublicTest  0.6039216 0.6313726 0.68235296 0.7411765 0.768...\n",
       "28711       4  PublicTest  0.23529412 0.3137255 0.43137255 0.45490196 0.3...\n",
       "28712       6  PublicTest  0.83137256 0.8 0.75686276 0.80784315 0.9215686...\n",
       "28713       3  PublicTest  0.3372549 0.33333334 0.32156864 0.30980393 0.3..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilan hasil df_public_test dataframe setelah normalisasi\n",
    "df_public_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom emotion: Jika ini adalah label kelas, awalnya tipe object maka bisa mengubahnya menjadi tipe data numerik menggunakan LabelEncoder dari scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "combined_df_train['emotion'] = le.fit_transform(combined_df_train['emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom resized_pixels: Jika kolom ini berisi string yang merepresentasikan array alias saat ini tipe object, maka perlu mengubahnya menjadi array numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi string piksel menjadi array NumPy data train\n",
    "combined_df_train['resized_pixels'] = combined_df_train['resized_pixels'].apply(\n",
    "    lambda x: np.fromstring(x, sep=' ').astype(np.float32).reshape(100, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6104 entries, 0 to 6103\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   emotion         6104 non-null   int64 \n",
      " 1   usage           3052 non-null   object\n",
      " 2   resized_pixels  6104 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi string piksel menjadi array NumPy data test\n",
    "df_public_test.loc[:, 'resized_pixels'] = df_public_test['resized_pixels'].apply(\n",
    "    lambda x: np.fromstring(x, sep=' ').astype(np.float32).reshape(100, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Pastikan semua entri memiliki ukuran 100x100\n",
    "print(combined_df_train['resized_pixels'].apply(lambda x: x.shape == (100, 100)).all())\n",
    "print(df_public_test['resized_pixels'].apply(lambda x: x.shape == (100, 100)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.53333336, 0.5058824, 0.4509804, 0.39215687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.09803922, 0.09019608, 0.07058824, 0.066666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.8980392, 0.8862745, 0.87058824, 0.84705883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.8627451, 0.8745098, 0.88235295, 0.8980392,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>[[0.2784314, 0.30980393, 0.3647059, 0.42352942...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     usage                                     resized_pixels\n",
       "0        0  Training  [[0.53333336, 0.5058824, 0.4509804, 0.39215687...\n",
       "1        0  Training  [[0.09803922, 0.09019608, 0.07058824, 0.066666...\n",
       "2        0  Training  [[0.8980392, 0.8862745, 0.87058824, 0.84705883...\n",
       "3        0  Training  [[0.8627451, 0.8745098, 0.88235295, 0.8980392,...\n",
       "4        0  Training  [[0.2784314, 0.30980393, 0.3647059, 0.42352942..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan informasi dataframe setelah normalisasi\n",
    "combined_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>usage</th>\n",
       "      <th>resized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>0</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.99607843, 0.99607843, 0.99607843, 0.996078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>1</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.6039216, 0.6313726, 0.68235296, 0.7411765,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>4</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.23529412, 0.3137255, 0.43137255, 0.4549019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>6</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.83137256, 0.8, 0.75686276, 0.80784315, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28713</th>\n",
       "      <td>3</td>\n",
       "      <td>PublicTest</td>\n",
       "      <td>[[0.3372549, 0.33333334, 0.32156864, 0.3098039...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion       usage                                     resized_pixels\n",
       "28709       0  PublicTest  [[0.99607843, 0.99607843, 0.99607843, 0.996078...\n",
       "28710       1  PublicTest  [[0.6039216, 0.6313726, 0.68235296, 0.7411765,...\n",
       "28711       4  PublicTest  [[0.23529412, 0.3137255, 0.43137255, 0.4549019...\n",
       "28712       6  PublicTest  [[0.83137256, 0.8, 0.75686276, 0.80784315, 0.9...\n",
       "28713       3  PublicTest  [[0.3372549, 0.33333334, 0.32156864, 0.3098039..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan informasi dataframe setelah normalisasi\n",
    "df_public_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixup Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define function Mixup image and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_images_labels(images, labels, alpha=0.2):\n",
    "    \"\"\"Menerapkan Mixup Augmentation pada dua gambar dan label.\n",
    "    \n",
    "    Args:\n",
    "        images (tensor): Tensor gambar-gambar dengan shape (batch_size, channels, height, width).\n",
    "        labels (tensor): Tensor one-hot encoded label dengan shape (batch_size, num_classes).\n",
    "        alpha (float): Parameter distribusi Beta untuk campuran.\n",
    "\n",
    "    Returns:\n",
    "        mixed_images: Gambar campuran.\n",
    "        mixed_labels: Label campuran.\n",
    "    \"\"\"\n",
    "    # Ambil nilai lambda dari distribusi Beta\n",
    "    lambda_val = np.random.beta(alpha, alpha)\n",
    "    \n",
    "    # Pilih dua indeks acak\n",
    "    index = torch.randperm(images.size(0))\n",
    "    \n",
    "    # Gabungkan dua gambar\n",
    "    mixed_images = lambda_val * images + (1 - lambda_val) * images[index, :]\n",
    "    \n",
    "    # Gabungkan label\n",
    "    mixed_labels = lambda_val * labels + (1 - lambda_val) * labels[index, :]\n",
    "    \n",
    "    return mixed_images, mixed_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define function for data preparation before mixup: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan gambar dalam format tensor dan normalisasi ke [0, 1]\n",
    "def prepare_images_labels(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        # Ambil pixel dan konversi ke array numpy\n",
    "        pixels = np.array(df['resized_pixels'][i].split(), dtype=np.float32).reshape(100, 100) / 255.0\n",
    "        \n",
    "        # Tambahkan channel dimension untuk tensor (1 channel karena grayscale)\n",
    "        images.append(pixels[np.newaxis, :, :])\n",
    "        \n",
    "        # Ambil label (ekspresi) dan ubah menjadi one-hot encoding\n",
    "        label = df['emotion'][i]\n",
    "        one_hot_label = np.zeros(8)  # Misal 8 kelas ekspresi\n",
    "        one_hot_label[label] = 1\n",
    "        labels.append(one_hot_label)\n",
    "\n",
    "    # Ubah list ke tensor\n",
    "    images = torch.tensor(np.array(images), dtype=torch.float32)\n",
    "    labels = torch.tensor(np.array(labels), dtype=torch.float32)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiapkan gambar dan label dari combined_df\n",
    "images, labels = prepare_images_labels(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Processing Mixup Augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size untuk Mixup Augmentation\n",
    "batch_size = 64  # Batch size 64\n",
    "\n",
    "# Acak gambar dan label untuk setiap batch\n",
    "for i in tqdm(range(0, len(images), batch_size)):\n",
    "    batch_images = images[i:i+batch_size]\n",
    "    batch_labels = labels[i:i+batch_size]\n",
    "    \n",
    "    # Terapkan Mixup Augmentation\n",
    "    mixed_images, mixed_labels = mixup_images_labels(batch_images, batch_labels, alpha=0.2)\n",
    "\n",
    "# (Selanjutnya, mixed_images dan mixed_labels dapat digunakan untuk training model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the result of mixup augmented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_image = mixed_images[0, 0]  # Ambil gambar pertama dari saluran pertama\n",
    "\n",
    "# Ubah tensor ke numpy array\n",
    "image = mixed_image.detach().numpy()  # Mengubah tensor menjadi numpy array\n",
    "\n",
    "# Denormalisasi jika perlu, misal dari rentang [-1, 1] ke [0, 255]\n",
    "image = (image * 0.5 + 0.5) * 255  # Skala ulang ke [0, 255]\n",
    "\n",
    "# Pastikan untuk mengubah tipe data menjadi uint8\n",
    "image = (image * 255).astype(np.uint8)\n",
    "\n",
    "# Tampilkan gambar\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Hilangkan sumbu\n",
    "plt.title(\"Mixed Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konversi DataFrame ke Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image = torch.tensor(self.dataframe['resized_pixels'].iloc[idx], dtype=torch.float32).view(1, 100, 100)  # Jika gambar 100x100\n",
    "        # label = torch.tensor(self.dataframe['emotion'].iloc[idx], dtype=torch.long)\n",
    "        image = torch.tensor(self.dataframe['resized_pixels'].iloc[idx], dtype=torch.float32).unsqueeze(0)  # Sudah 100x100, hanya tambah channel dimension\n",
    "        label = torch.tensor(self.dataframe['emotion'].iloc[idx], dtype=torch.long)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi dataset\n",
    "train_dataset = EmotionDataset(combined_df_train)\n",
    "test_dataset = EmotionDataset(df_public_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Inisialisasi DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBP circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mendapatkan intensitas piksel tetangga menggunakan interpolasi bilinear\n",
    "def get_pixel_value(img, center, x, y):\n",
    "    # Jika tetangga berada di dalam batas gambar\n",
    "    if x >= 0 and x < img.shape[0] and y >= 0 and y < img.shape[1]:\n",
    "        return img[int(x)][int(y)]\n",
    "    else:\n",
    "        return center\n",
    "\n",
    "# Fungsi untuk menghitung Circular LBP pada piksel (x, y)\n",
    "def lbp_calculated_pixel(img, x, y, radius, neighbors):\n",
    "    center = img[x][y]\n",
    "    values = []\n",
    "    \n",
    "    # Looping untuk mengambil nilai tetangga dalam pola melingkar\n",
    "    for n in range(neighbors):\n",
    "        theta = 2 * math.pi * n / neighbors  # Sudut\n",
    "        x_n = x + radius * math.sin(theta)   # Koordinat tetangga dalam pola melingkar\n",
    "        y_n = y + radius * math.cos(theta)\n",
    "        neighbor_value = get_pixel_value(img, center, x_n, y_n)\n",
    "        values.append(1 if neighbor_value >= center else 0)\n",
    "    \n",
    "    # Menghitung nilai biner LBP\n",
    "    lbp_value = 0\n",
    "    for i in range(len(values)):\n",
    "        lbp_value += values[i] * (1 << i)  # 1 << i adalah 2^i\n",
    "    \n",
    "    return lbp_value\n",
    "\n",
    "# Fungsi untuk menghitung Circular LBP untuk seluruh citra\n",
    "def calculate_lbp_image(img, radius=1, neighbors=8):\n",
    "    height, width = img.shape\n",
    "    lbp_image = np.zeros((height, width), dtype=np.uint32)  # Mengubah tipe data ke uint32 untuk mendukung nilai besar\n",
    "    \n",
    "    for i in range(radius, height - radius):\n",
    "        for j in range(radius, width - radius):\n",
    "            lbp_image[i, j] = lbp_calculated_pixel(img, i, j, radius, neighbors)\n",
    "    \n",
    "    # Normalisasi jika diperlukan (mengembalikan nilai dalam rentang 0-255)\n",
    "    lbp_image_normalized = np.uint8(lbp_image / lbp_image.max() * 255)\n",
    "    \n",
    "    return lbp_image_normalized\n",
    "\n",
    "# Fungsi untuk menampilkan hasil\n",
    "# def show_output(original_img, lbp_img):\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "#     # Gambar asli (grayscale)\n",
    "#     axs[0].imshow(original_img, cmap='gray')\n",
    "#     axs[0].set_title('Original Grayscale Image')\n",
    "    \n",
    "#     # Hasil LBP\n",
    "#     axs[1].imshow(lbp_img, cmap='gray')\n",
    "#     axs[1].set_title('Circular LBP Image')\n",
    "    \n",
    "#     plt.show()\n",
    "\n",
    "# Fungsi untuk ekstraksi fitur LBP dari batch gambar\n",
    "def lbp_feature_extraction_batch(images, radius=3, neighbors=24):\n",
    "    lbp_features = []\n",
    "    for img in images:\n",
    "        lbp_img = calculate_lbp_image(img.squeeze().cpu().numpy(), radius, neighbors)  # Ekstraksi LBP dari gambar\n",
    "        lbp_hist, _ = np.histogram(lbp_img.ravel(), bins=np.arange(0, neighbors + 3), range=(0, neighbors + 2))\n",
    "        lbp_hist = lbp_hist.astype(\"float\")\n",
    "        lbp_hist /= lbp_hist.sum()  # Normalisasi histogram\n",
    "        lbp_features.append(lbp_hist)\n",
    "\n",
    "    return np.array(lbp_features)\n",
    "    \n",
    "neighbors=24 # samakan dengan tabel dari referensi circular lbp ini yang optimal\n",
    "\n",
    "# Definisikan ukuran fitur LBP\n",
    "lbp_feature_size = neighbors + 2  # Misalnya 26 untuk 24 neighbors  \n",
    "\n",
    "# Main function\n",
    "# def lbp_feature_extraction(image):\n",
    "#     # Membaca citra\n",
    "#     # image_file = '../src/lenna.jpg'\n",
    "#     image_file = image\n",
    "#     img_bgr = cv2.imread(image_file)\n",
    "#     img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Hitung LBP dengan radius 3 dan 24 tetangga\n",
    "#     lbp_img = calculate_lbp_image(img_gray, radius=3, neighbors=24)\n",
    "    \n",
    "#     # Tampilkan hasilnya\n",
    "#     show_output(img_gray, lbp_img)\n",
    "\n",
    "#     return lbp_img\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     lbp_img = lbp_feature_extraction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengonversi Output LBP menjadi Vektor dan Menghubungkan ke FC Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        # MLP\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // ratio, kernel_size=1, bias=False)\n",
    "        self.fc2 = nn.Conv2d(in_channels // ratio, in_channels, kernel_size=1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# Spatial Attention Module\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# CBAM Module (Channel + Spatial Attention)\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, ratio)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.channel_attention(x)\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ResNet18_CBAM, self).__init__()\n",
    "        \n",
    "        self.dropout_percentage = 0.5\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # BLOCK-1 (starting block) input=(224x224) output=(56x56)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        \n",
    "        # CBAM after block1\n",
    "        self.cbam1 = CBAM(64)\n",
    "\n",
    "        # BLOCK-2 (1) input=(56x56) output = (56x56)\n",
    "        self.conv2_1_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_1_1 = nn.BatchNorm2d(64)\n",
    "        self.conv2_1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_1_2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-2 (2)\n",
    "        self.conv2_2_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_2_1 = nn.BatchNorm2d(64)\n",
    "        self.conv2_2_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_2_2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # CBAM after block2\n",
    "        self.cbam2 = CBAM(64)\n",
    "        \n",
    "        # BLOCK-3 (1) input=(56x56) output = (28x28)\n",
    "        self.conv3_1_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm3_1_1 = nn.BatchNorm2d(128)\n",
    "        self.conv3_1_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_1_2 = nn.BatchNorm2d(128)\n",
    "        self.concat_adjust_3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout3_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-3 (2)\n",
    "        self.conv3_2_1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_2_1 = nn.BatchNorm2d(128)\n",
    "        self.conv3_2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_2_2 = nn.BatchNorm2d(128)\n",
    "        self.dropout3_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # CBAM after block3\n",
    "        self.cbam3 = CBAM(128)\n",
    "\n",
    "        # BLOCK-4 (1) input=(28x28) output = (14x14)\n",
    "        self.conv4_1_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm4_1_1 = nn.BatchNorm2d(256)\n",
    "        self.conv4_1_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_1_2 = nn.BatchNorm2d(256)\n",
    "        self.concat_adjust_4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout4_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-4 (2)\n",
    "        self.conv4_2_1 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_2_1 = nn.BatchNorm2d(256)\n",
    "        self.conv4_2_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_2_2 = nn.BatchNorm2d(256)\n",
    "        self.dropout4_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # CBAM after block4\n",
    "        self.cbam4 = CBAM(256)\n",
    "\n",
    "        # BLOCK-5 (1) input=(14x14) output = (7x7)\n",
    "        self.conv5_1_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm5_1_1 = nn.BatchNorm2d(512)\n",
    "        self.conv5_1_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_1_2 = nn.BatchNorm2d(512)\n",
    "        self.concat_adjust_5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout5_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-5 (2)\n",
    "        self.conv5_2_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv5_2_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_2_2 = nn.BatchNorm2d(512)\n",
    "        self.dropout5_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # CBAM after block5\n",
    "        self.cbam5 = CBAM(512)\n",
    "        \n",
    "        # Final Block input=(7x7) \n",
    "        # self.avgpool = nn.AvgPool2d(kernel_size=(7, 7), stride=(7, 7))  # Mengubah output menjadi (512, 1, 1)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(4, 4), stride=(4, 4))  # Output akan menjadi (512, 1, 1)\n",
    "        self.fc = nn.Linear(in_features=1 * 1 * 512, out_features=1000)  # 512 dari avgpool\n",
    "        self.out = nn.Linear(in_features=1000, out_features=n_classes)  # n_classes sesuai dengan jumlah kelas\n",
    "        # END\n",
    "\n",
    "    def forward(self, x):\n",
    "        # block 1 --> Starting block\n",
    "        x = self.relu(self.batchnorm1(self.conv1(x)))\n",
    "        op1 = self.maxpool1(x)\n",
    "        op1 = self.cbam1(op1)\n",
    "        # print(f\"Output after Block 1: {op1.shape}\")  # Cek ukuran output\n",
    "        \n",
    "        # block2 - 1\n",
    "        x = self.relu(self.batchnorm2_1_1(self.conv2_1_1(op1)))    # conv2_1 \n",
    "        x = self.batchnorm2_1_2(self.conv2_1_2(x))                 # conv2_1\n",
    "        x = self.dropout2_1(x)\n",
    "        # block2 - Adjust - No adjust in this layer as dimensions are already same\n",
    "        # block2 - Concatenate 1\n",
    "        op2_1 = self.relu(x + op1)\n",
    "        # block2 - 2\n",
    "        x = self.relu(self.batchnorm2_2_1(self.conv2_2_1(op2_1)))  # conv2_2 \n",
    "        x = self.batchnorm2_2_2(self.conv2_2_2(x))                 # conv2_2\n",
    "        x = self.dropout2_2(x)\n",
    "        # op - block2\n",
    "        op2 = self.relu(x + op2_1)\n",
    "        op2 = self.cbam2(op2)\n",
    "        # print(f\"Output after Block 2: {op2.shape}\")  # Cek ukuran output\n",
    "        \n",
    "        # block3 - 1[Convolution block]\n",
    "        x = self.relu(self.batchnorm3_1_1(self.conv3_1_1(op2)))    # conv3_1\n",
    "        x = self.batchnorm3_1_2(self.conv3_1_2(x))                 # conv3_1\n",
    "        x = self.dropout3_1(x)\n",
    "        # block3 - Adjust\n",
    "        op2 = self.concat_adjust_3(op2) # SKIP CONNECTION\n",
    "        # block3 - Concatenate 1\n",
    "        op3_1 = self.relu(x + op2)\n",
    "        # block3 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm3_2_1(self.conv3_2_1(op3_1)))  # conv3_2\n",
    "        x = self.batchnorm3_2_2(self.conv3_2_2(x))                 # conv3_2 \n",
    "        x = self.dropout3_2(x)\n",
    "        # op - block3\n",
    "        op3 = self.relu(x + op3_1)\n",
    "        op3 = self.cbam3(op3)\n",
    "        # print(f\"Output after Block 3: {op3.shape}\")  # Cek ukuran output\n",
    "\n",
    "        # block4 - 1[Convolition block]\n",
    "        x = self.relu(self.batchnorm4_1_1(self.conv4_1_1(op3)))    # conv4_1\n",
    "        x = self.batchnorm4_1_2(self.conv4_1_2(x))                 # conv4_1\n",
    "        x = self.dropout4_1(x)\n",
    "        # block4 - Adjust\n",
    "        op3 = self.concat_adjust_4(op3) # SKIP CONNECTION\n",
    "        # block4 - Concatenate 1\n",
    "        op4_1 = self.relu(x + op3)\n",
    "        # block4 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm4_2_1(self.conv4_2_1(op4_1)))  # conv4_2\n",
    "        x = self.batchnorm4_2_2(self.conv4_2_2(x))                 # conv4_2\n",
    "        x = self.dropout4_2(x)\n",
    "        # op - block4\n",
    "        op4 = self.relu(x + op4_1)\n",
    "        op4 = self.cbam4(op4)\n",
    "        # print(f\"Output after Block 4: {op4.shape}\")  # Cek ukuran output\n",
    "\n",
    "        # block5 - 1[Convolution Block]\n",
    "        x = self.relu(self.batchnorm5_1_1(self.conv5_1_1(op4)))    # conv5_1\n",
    "        x = self.batchnorm5_1_2(self.conv5_1_2(x))                 # conv5_1\n",
    "        x = self.dropout5_1(x)\n",
    "        # block5 - Adjust\n",
    "        op4 = self.concat_adjust_5(op4) # SKIP CONNECTION\n",
    "        # block5 - Concatenate 1\n",
    "        op5_1 = self.relu(x + op4)\n",
    "        # block5 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm5_2_1(self.conv5_2_1(op5_1)))  # conv5_2\n",
    "        x = self.batchnorm5_2_2(self.conv5_2_2(x))                 # conv5_2\n",
    "        x = self.dropout5_2(x)\n",
    "        # op - block5\n",
    "        op5 = self.relu(x + op5_1)\n",
    "        op5 = self.cbam5(op5)\n",
    "        # print(f\"Output after Block 5: {op5.shape}\")  # Cek ukuran output\n",
    "        \n",
    "        # final operations\n",
    "        x = self.avgpool(op5)\n",
    "        # print(f\"Shape after avgpool: {x.shape}\")\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(f\"Shape after flatten: {x.shape}\")\n",
    "        xfeatures = self.fc(x)\n",
    "        # print(f\"Output after fc: {x.shape}\")  # Cek ukuran output\n",
    "        # x = self.out(x) # Jangan panggil self.out\n",
    "        # print(f\"Output self.out: {x.shape}\")  # Cek ukuran output\n",
    "        return xfeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, n_classes, lbp_feature_size):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.resnet = ResNet18_CBAM(n_classes)\n",
    "        self.fc_lbp = nn.Linear(lbp_feature_size, 128)  # Ubah lbp_feature_size sesuai ukuran LBP\n",
    "        self.fc_combined = nn.Linear(128 + 1000, n_classes)  # Gabungkan output LBP dan ResNet\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ekstraksi fitur LBP\n",
    "        lbp_features = lbp_feature_extraction_batch(x)  # Ekstrak fitur LBP\n",
    "        lbp_features = torch.from_numpy(lbp_features).float().to(x.device)  # Konversi ke tensor dan pindahkan ke device\n",
    "        lbp_features = lbp_features.view(lbp_features.size(0), -1)  # Flatten jika perlu\n",
    "        # print(f\"LBP feature size: {lbp_features.shape}\")\n",
    "        \n",
    "        # Proses fitur LBP\n",
    "        lbp_features = self.fc_lbp(lbp_features)\n",
    "        # print(f\"Processed LBP feature size: {lbp_features.shape}\")\n",
    "        \n",
    "        # Proses melalui ResNet (output fitur sebelum klasifikasi akhir)\n",
    "        resnet_output = self.resnet(x)  # Output [32,1000]\n",
    "        # print(f\"ResNet output size: {resnet_output.shape}\")\n",
    "        \n",
    "        # Gabungkan output LBP dan ResNet\n",
    "        combined = torch.cat((lbp_features, resnet_output), dim=1)  # [32,1128]\n",
    "        # print(f\"Combined feature size: {combined.shape}\")\n",
    "        \n",
    "        # Proses melalui fully connected layer\n",
    "        output = self.fc_combined(combined)  # [32,7]\n",
    "        # print(f\"Output after fc_combined: {output.shape}\")\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model dengan Batch Processing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memastikan tidak ada diluar rentang 0-6 pada label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor(combined_df_train['emotion'].values)\n",
    "print(labels.unique())  # Pastikan label tidak ada yang out-of-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')\n",
    "# model = CombinedModel(n_classes=7, lbp_feature_size=lbp_feature_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_16664\\1482160649.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak ada checkpoint, memulai training dari awal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 [Training]: 100%|██████████| 96/96 [26:50<00:00, 16.77s/it, Training Loss=0.00655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Training Loss: 0.7787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 [Validating]: 100%|██████████| 57/57 [14:55<00:00, 15.71s/it, Validation Loss=9.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.2845, Accuracy: 16.91%\n",
      "Model dengan akurasi terbaik disimpan: 16.91% pada epoch 1\n",
      "Model terakhir disimpan setelah epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300 [Training]: 100%|██████████| 96/96 [25:10<00:00, 15.74s/it, Training Loss=0.00563] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Training Loss: 0.8841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300 [Validating]: 100%|██████████| 57/57 [15:15<00:00, 16.06s/it, Validation Loss=10.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6997, Accuracy: 16.91%\n",
      "Model terakhir disimpan setelah epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300 [Training]: 100%|██████████| 96/96 [29:15<00:00, 18.28s/it, Training Loss=0.0014]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Training Loss: 1.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300 [Validating]: 100%|██████████| 57/57 [15:29<00:00, 16.30s/it, Validation Loss=15.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 10.7793, Accuracy: 16.91%\n",
      "Model terakhir disimpan setelah epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300 [Training]:  64%|██████▎   | 61/96 [17:49<10:13, 17.53s/it, Training Loss=0]       \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     34\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Ando File 4 Kuliah\\A SKRIPSI\\RISETku\\KERJA\\CODE\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m, in \u001b[0;36mCombinedModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Ekstraksi fitur LBP\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     lbp_features \u001b[38;5;241m=\u001b[39m \u001b[43mlbp_feature_extraction_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ekstrak fitur LBP\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     lbp_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(lbp_features)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# Konversi ke tensor dan pindahkan ke device\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     lbp_features \u001b[38;5;241m=\u001b[39m lbp_features\u001b[38;5;241m.\u001b[39mview(lbp_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten jika perlu\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 61\u001b[0m, in \u001b[0;36mlbp_feature_extraction_batch\u001b[1;34m(images, radius, neighbors)\u001b[0m\n\u001b[0;32m     59\u001b[0m lbp_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m---> 61\u001b[0m     lbp_img \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_lbp_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ekstraksi LBP dari gambar\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     lbp_hist, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(lbp_img\u001b[38;5;241m.\u001b[39mravel(), bins\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, neighbors \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m), \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, neighbors \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     63\u001b[0m     lbp_hist \u001b[38;5;241m=\u001b[39m lbp_hist\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[44], line 36\u001b[0m, in \u001b[0;36mcalculate_lbp_image\u001b[1;34m(img, radius, neighbors)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(radius, height \u001b[38;5;241m-\u001b[39m radius):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(radius, width \u001b[38;5;241m-\u001b[39m radius):\n\u001b[1;32m---> 36\u001b[0m         lbp_image[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mlbp_calculated_pixel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Normalisasi jika diperlukan (mengembalikan nilai dalam rentang 0-255)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m lbp_image_normalized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(lbp_image \u001b[38;5;241m/\u001b[39m lbp_image\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\n",
      "Cell \u001b[1;32mIn[44], line 20\u001b[0m, in \u001b[0;36mlbp_calculated_pixel\u001b[1;34m(img, x, y, radius, neighbors)\u001b[0m\n\u001b[0;32m     18\u001b[0m     y_n \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m radius \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(theta)\n\u001b[0;32m     19\u001b[0m     neighbor_value \u001b[38;5;241m=\u001b[39m get_pixel_value(img, center, x_n, y_n)\n\u001b[1;32m---> 20\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m neighbor_value \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m center \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Menghitung nilai biner LBP\u001b[39;00m\n\u001b[0;32m     23\u001b[0m lbp_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Inisialisasi model dan optimasi\n",
    "model = CombinedModel(n_classes=7, lbp_feature_size=lbp_feature_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.1, weight_decay=0.0001)\n",
    "\n",
    "# Variabel untuk menyimpan akurasi terbaik\n",
    "best_accuracy = 0.0\n",
    "start_epoch = 0  # Epoch awal default\n",
    "\n",
    "# Jika ingin melanjutkan dari checkpoint\n",
    "checkpoint_path = 'model_checkpoint_latest.pt'  # Nama file checkpoint terakhir\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    best_accuracy = checkpoint['accuracy']\n",
    "    start_epoch = checkpoint['epoch']  # Mulai dari epoch terakhir\n",
    "    print(f\"Melanjutkan dari epoch {start_epoch+1}, Akurasi terbaik: {best_accuracy:.2f}%\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Tidak ada checkpoint, memulai training dari awal.\")\n",
    "\n",
    "# Training loop dengan validasi\n",
    "epochs = 300\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    progress_bar_train = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\")\n",
    "    \n",
    "    for images, labels in progress_bar_train:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        progress_bar_train.set_postfix({'Training Loss': loss.item()})\n",
    "    \n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Average Training Loss: {average_loss:.4f}\")\n",
    "\n",
    "    # Validasi\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar_val = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs} [Validating]\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress_bar_val:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            progress_bar_val.set_postfix({'Validation Loss': loss.item()})\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Simpan model jika akurasi lebih baik dari sebelumnya (model dengan akurasi terbaik)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        checkpoint_best = {\n",
    "            'epoch': epoch + 1,  # Simpan epoch berikutnya\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'accuracy': accuracy,\n",
    "        }\n",
    "        torch.save(checkpoint_best, 'model_checkpoint_best.pt')\n",
    "        print(f\"Model dengan akurasi terbaik disimpan: {accuracy:.2f}% pada epoch {epoch + 1}\")\n",
    "\n",
    "    # Simpan model terakhir yang di-train (model terakhir setiap epoch)\n",
    "    checkpoint_latest = {\n",
    "        'epoch': epoch + 1,  # Simpan epoch berikutnya\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    torch.save(checkpoint_latest, 'model_checkpoint_latest.pt')\n",
    "    print(f\"Model terakhir disimpan setelah epoch {epoch + 1}\")\n",
    "\n",
    "print(\"Training dan validasi selesai.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
